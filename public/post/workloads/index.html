
<!DOCTYPE html>
<html
  lang="en"
  data-figures=""
  
    class="page"
  
  
  
    data-mode="dim"
  >
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
<title>Mastering Kubernetes: Dive into Workloads APIs | Clarity</title>
<meta charset="utf-8">

<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">


<meta property="og:locale" content="en" />

<meta property="og:type" content="article">
<meta name="description" content="You might be new to Kubernetes or you might have been working with it for a while. No matter your experience level, you might not be aware of all the Kubernetes ‚Ä¶" />
<meta name="twitter:card" content="summary" />
<meta name="twitter:creator" content="@vfarcic">
<meta name="twitter:title" content="Mastering Kubernetes: Dive into Workloads APIs" />
<meta name="twitter:image" content="http://localhost:1313/images/thumbnail.png"/>
<meta property="og:url" content="http://localhost:1313/post/workloads/" />
<meta property="og:title" content="Mastering Kubernetes: Dive into Workloads APIs" />
<meta property="og:description" content="You might be new to Kubernetes or you might have been working with it for a while. No matter your experience level, you might not be aware of all the Kubernetes ‚Ä¶" />
<meta property="og:image" content="http://localhost:1313/images/thumbnail.png" />

<link rel="apple-touch-icon" sizes="180x180" href="http://localhost:1313/icons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/icons/favicon-32x32.png">
<link rel="manifest" href="http://localhost:1313/icons/site.webmanifest">

<link rel="canonical" href="http://localhost:1313/post/workloads/">



<link rel="preload" href="http://localhost:1313/css/styles.42e2c5f6d8cf9c52872666f8d8b2678ad0c426978b9d78aff3c33b7a1e7f6f97f54bcdaf0518a25fb0fe26367d04f8b07c683b3b38b331cb098daadee06b1f3e.css" integrity = "sha512-QuLF9tjPnFKHJmb42LJnitDEJpeLnXiv88M7eh5/b5f1S82vBRiiX7D&#43;JjZ9BPiwfGg7OzizMcsJjare4GsfPg==" as="style" crossorigin="anonymous">



<link rel="preload" href="http://localhost:1313/en/js/bundle.0d036cc8bad2080f4c50d1ad5c14f6106a56b6d12ac69457cb6219c7fcb4181e1ecae48e5a844297763c02a18426d0f0811d2cb368792861cb42618660b894d9.js" as="script" integrity=
"sha512-DQNsyLrSCA9MUNGtXBT2EGpWttEqxpRXy2IZx/y0GB4eyuSOWoRCl3Y8AqGEJtDwgR0ss2h5KGHLQmGGYLiU2Q==" crossorigin="anonymous">


<link rel="stylesheet" type="text/css" href="http://localhost:1313/css/styles.42e2c5f6d8cf9c52872666f8d8b2678ad0c426978b9d78aff3c33b7a1e7f6f97f54bcdaf0518a25fb0fe26367d04f8b07c683b3b38b331cb098daadee06b1f3e.css" integrity="sha512-QuLF9tjPnFKHJmb42LJnitDEJpeLnXiv88M7eh5/b5f1S82vBRiiX7D&#43;JjZ9BPiwfGg7OzizMcsJjare4GsfPg==" crossorigin="anonymous">

  </head>
  <body
    data-code="7"
    data-lines="false"
    id="documentTop"
    data-lang="en"
  >

<header class="nav_header" >
  <nav class="nav"><a href="/"><img src="/dot-narrow-yellow-bg.png" style="width: 25%;"/></a>
    <div class='nav_body nav_body_left'>
      
      
      
        

  <div class="nav_parent">
    <a href="http://localhost:1313/" class="nav_item" title="Home">Home </a>
  </div>
  <div class="nav_parent">
    <a href="http://localhost:1313/post/" class="nav_item" title="Posts">Posts </a>
  </div>
      
      <div class="nav_parent">
        <a href="#" class="nav_item">üåê</a>
        <div class="nav_sub">
          <span class="nav_child"></span>
          
          <a href="http://localhost:1313/" class="nav_child nav_item">English</a>
          
          <a href="http://localhost:1313/pt/" class="nav_child nav_item">Portugu√™s</a>
          
        </div>
      </div>
<div class='follow'>
  <a href="https://youtube.com/@DevOpsToolkit">
    <svg class="icon">
  <title>youtube</title>
  <use xlink:href="#youtube"></use>
</svg>

  </a>
  <a href="https://github.com/vfarcic">
    <svg class="icon">
  <title>github</title>
  <use xlink:href="#github"></use>
</svg>

  </a>
  <a href="https://twitter.com/vfarcic">
    <svg class="icon">
  <title>twitter</title>
  <use xlink:href="#twitter"></use>
</svg>

  </a>
  <a href="https://linkedin.com/in/viktorfarcic/">
    <svg class="icon">
  <title>linkedin</title>
  <use xlink:href="#linkedin"></use>
</svg>

  </a>
<div class="color_mode">
  <input type="checkbox" class="color_choice" id="mode">
</div>

</div>

    </div>
  </nav>
</header>

    <main>
  
<div class="grid-inverse wrap content">
  <article class="post_content">
    <h1 class="post_title">Mastering Kubernetes: Dive into Workloads APIs</h1>
  <div class="post_meta">
    <span><svg class="icon">
  <title>calendar</title>
  <use xlink:href="#calendar"></use>
</svg>
</span>
    <span class="post_date">
      Apr 15, 2024</span>
    <span class="post_time"> ¬∑ 31 min read</span>
    <span class="page_only">&nbsp;¬∑
  <div class="post_share">
    Share on:
    <a href="https://twitter.com/intent/tweet?text=Mastering%20Kubernetes%3a%20Dive%20into%20Workloads%20APIs&url=http%3a%2f%2flocalhost%3a1313%2fpost%2fworkloads%2f&tw_p=tweetbutton" class="twitter" title="Share on Twitter" target="_blank" rel="nofollow">
      <svg class="icon">
  <title>twitter</title>
  <use xlink:href="#twitter"></use>
</svg>

    </a>
    <a href="https://www.facebook.com/sharer.php?u=http%3a%2f%2flocalhost%3a1313%2fpost%2fworkloads%2f&t=Mastering%20Kubernetes%3a%20Dive%20into%20Workloads%20APIs" class="facebook" title="Share on Facebook" target="_blank" rel="nofollow">
      <svg class="icon">
  <title>facebook</title>
  <use xlink:href="#facebook"></use>
</svg>

    </a>
    <a href="#linkedinshare" id = "linkedinshare" class="linkedin" title="Share on LinkedIn" rel="nofollow">
      <svg class="icon">
  <title>linkedin</title>
  <use xlink:href="#linkedin"></use>
</svg>

    </a>
    <a href="http://localhost:1313/post/workloads/" title="Copy Link" class="link link_yank">
      <svg class="icon">
  <title>copy</title>
  <use xlink:href="#copy"></use>
</svg>

    </a>
  </div>
  </span>
  </div>

    <div class="post_body"><p>You might be new to <strong>Kubernetes</strong> or you might have been working with it for a while. No matter your experience level, you might not be aware of all the <strong>Kubernetes Workload APIs</strong>.</p>
<div class="video">
  <iframe src="https://www.youtube.com/embed/U6weXlzQxoY?controls=1&rel=0" loading="lazy"></iframe>
</div>

<p>There are <strong>Pods</strong> as lower level, <strong>ReplicaSets</strong> and <strong>Jobs</strong> in between, and <strong>Deployments</strong>, <strong>StatefulSets</strong>, <strong>DaemonSets</strong>, and <strong>CronJobs</strong> on top. To make things more complicated, those are workload APIs baked into Kubernetes cluster and, on top of those, we can have more, much more.</p>
<p>Today we'll explore all of those. We'll see what is the purpose of each, when each of them should or should not be used for, and quite a few things.</p>
<p>Buckle up! We're about to dive into all Kubernetes workload resource types.</p>
<h2 id="setup">Setup</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">git clone https://github.com/vfarcic/kubernetes-demo
</span></span><span class="line"><span class="ln">2</span><span class="cl">
</span></span><span class="line"><span class="ln">3</span><span class="cl"><span class="nb">cd</span> kubernetes-demo
</span></span><span class="line"><span class="ln">4</span><span class="cl">
</span></span><span class="line"><span class="ln">5</span><span class="cl">git pull
</span></span><span class="line"><span class="ln">6</span><span class="cl">
</span></span><span class="line"><span class="ln">7</span><span class="cl">git checkout workloads
</span></span></code></pre></div><p><em>Make sure that Docker is up-and-running. We'll use it to create a KinD cluster.</em></p>
<p><em>Watch <a href="https://youtu.be/WiFLtcBvGMU">https://youtu.be/WiFLtcBvGMU</a> if you are not familiar with Devbox. Alternatively, you can skip Devbox and install all the tools listed in <code>devbox.json</code> yourself.</em></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">devbox shell
</span></span><span class="line"><span class="ln">2</span><span class="cl">
</span></span><span class="line"><span class="ln">3</span><span class="cl">kind create cluster --config kind.yaml
</span></span><span class="line"><span class="ln">4</span><span class="cl">
</span></span><span class="line"><span class="ln">5</span><span class="cl">kubectl create namespace a-team
</span></span></code></pre></div><h2 id="containers-in-kubernetes">Containers in Kubernetes</h2>
<p><strong>Containers</strong> are the base of everything running in Kubernetes. Everything ends up either running in a container or be managed by something running in a container.</p>
<p>Actually... that's not really true. It does not have to be containers. It could be <strong>WASM</strong> or it could be VMs managed by <strong>KubeVirt</strong>, or many other ways to run processes. Nevertheless, if we're talking about &quot;vanilla&quot; Kubernetes, it's all about containers. We package processes into container images and we run them as containers.</p>
<p>However... you need to pay attention to this one. We cannot run containers directly. There is no option in Kubernetes to say &quot;run this container&quot;. Containers are always wrapped into Pods, hence that is our starting point.</p>
<p>Let's take a look at what they are, how they work, and why you are unlikely to ever run them directly.</p>
<h2 id="pods-in-kubernetes">Pods in Kubernetes</h2>
<p>Pods are the base Kubernetes resources. Any type of a workload, at least among those baked in Kubernetes, ends up being a Pod.</p>
<p>So, <strong>what is a Pod?</strong></p>
<p>A Pod is <strong>a collection of one or more containers</strong>. Most of a time, a Pod contains a single container with your or someone else's application. On top of that, there might be additional containers for various purposes. For example, a service mesh might attach a container that deals with networking. Those are called <strong>side-car containers</strong>.</p>
<p>Here's an example.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">cat pod/base.yaml
</span></span></code></pre></div><p>The output is as follows.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="ln"> 1</span><span class="cl"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 2</span><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Pod</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 3</span><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 4</span><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">silly-demo</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 5</span><span class="cl"><span class="w">  </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 6</span><span class="cl"><span class="w">    </span><span class="nt">app.kubernetes.io/name</span><span class="p">:</span><span class="w"> </span><span class="l">silly-demo</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 7</span><span class="cl"><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 8</span><span class="cl"><span class="w">  </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 9</span><span class="cl"><span class="w">    </span>- <span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">ghcr.io/vfarcic/silly-demo:1.4.115</span><span class="w">
</span></span></span><span class="line"><span class="ln">10</span><span class="cl"><span class="w">      </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">silly-demo</span><span class="w">
</span></span></span><span class="line"><span class="ln">11</span><span class="cl"><span class="w">      </span><span class="nt">ports</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">12</span><span class="cl"><span class="w">        </span>- <span class="nt">containerPort</span><span class="p">:</span><span class="w"> </span><span class="m">8080</span><span class="w">    
</span></span></span><span class="line"><span class="ln">13</span><span class="cl"><span class="w">      </span><span class="nt">readinessProbe</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">14</span><span class="cl"><span class="w">        </span><span class="nt">httpGet</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">15</span><span class="cl"><span class="w">          </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l">/</span><span class="w">
</span></span></span><span class="line"><span class="ln">16</span><span class="cl"><span class="w">          </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="m">8080</span><span class="w">
</span></span></span><span class="line"><span class="ln">17</span><span class="cl"><span class="w">      </span><span class="nt">resources</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">18</span><span class="cl"><span class="w">        </span><span class="nt">limits</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">19</span><span class="cl"><span class="w">          </span><span class="nt">cpu</span><span class="p">:</span><span class="w"> </span><span class="l">250m</span><span class="w">
</span></span></span><span class="line"><span class="ln">20</span><span class="cl"><span class="w">          </span><span class="nt">memory</span><span class="p">:</span><span class="w"> </span><span class="l">256Mi</span><span class="w">
</span></span></span><span class="line"><span class="ln">21</span><span class="cl"><span class="w">        </span><span class="nt">requests</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">22</span><span class="cl"><span class="w">          </span><span class="nt">cpu</span><span class="p">:</span><span class="w"> </span><span class="l">125m</span><span class="w">
</span></span></span><span class="line"><span class="ln">23</span><span class="cl"><span class="w">          </span><span class="nt">memory</span><span class="p">:</span><span class="w"> </span><span class="l">128Mi</span><span class="w">
</span></span></span></code></pre></div><p>That's a <code>Pod</code> manifest containing a list of <code>containers</code>. In this case there is only one based on the <code>silly-demo</code> image. It has a <code>name</code>, a list of <code>ports</code>, a <code>readinessProbe</code> that is used by Kubernetes to deduce whether it is healty, and resource <code>limits</code> and <code>requests</code> that are used to deduce how much <code>memory</code> and <code>cpu</code> we expect it to use.</p>
<p>If we apply that manifest,...</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">kubectl --namespace a-team apply --filename pod/base.yaml
</span></span></code></pre></div><p>...and retrieve all the Pods in that Namespace,...</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">kubectl --namespace a-team get pods
</span></span></code></pre></div><p>The output is as follows.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln">1</span><span class="cl">NAME       READY STATUS  RESTARTS AGE
</span></span><span class="line"><span class="ln">2</span><span class="cl">silly-demo 1/1   Running 0        7s
</span></span></code></pre></div><p>...we can see that it is <code>running</code>.</p>
<img src="diag-01.png" style="width:50%; float:right; padding: 10px">
<p>We sent a request to Kubernetes API  to apply a manifest containing a Pod with a single container. As a result, Kubernetes started running that container  wrapped inside a Pod . That's the container with our application.</p>
<p>Here's a thing though.</p>
<p>You will probably <strong>never run Pods directly</strong>. That would be foolish since Pods alone are not fault tollerant, are complicated to replace with new releases safely, and so on and so forth. Pods are building blocks that should be managed by other types of workloads.</p>
<p>Here's an example. Let's say that something happened to a Pod. Let's say that it crashed, that it dissapeared. What would happen in that case?</p>
<p>We can simulate that by deleting the Pod.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">kubectl --namespace a-team delete pod silly-demo
</span></span></code></pre></div><p>You can probably guess what happens when we delete something.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">kubectl --namespace a-team get pods
</span></span></code></pre></div><p>The output is as follows.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln">1</span><span class="cl">No resources found in a-team namespace.
</span></span></code></pre></div><p>It dissapeared. It's gone, and it's not coming back.</p>
<p>Now, if that was our intention, that should be the expected outcome. But what if that's not what we wanted. What if our goal is to have that Pod running forever and ever, or until we choose to replace with with a newer release? What if we would like to have some kind of a &quot;contract&quot; that says &quot;run this Pod no matter what happens.&quot;</p>
<p>In that case, we would need something else. We would need a ReplicaSet.</p>
<h2 id="replicasets-in-kubernetes">ReplicaSets in Kubernetes</h2>
<p>A <strong>ReplicaSet</strong> is a Kubernetes resource that ensures there is always a <strong>stable set of running pods</strong> for a specific workload. It is a &quot;special&quot; type of resource that ensures that the contract between you and Kubernetes is maintained. It is a resource that allows us to say: &quot;<strong>I want this number of Pods with those specifications</strong>. Make sure that is fullfilled no matter what happens. The world might end, but those Pods should still be running.&quot;</p>
<p>Here's an example.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">cat replicaset/base.yaml
</span></span></code></pre></div><p>The output is as follows.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="ln"> 1</span><span class="cl"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">apps/v1</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 2</span><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">ReplicaSet</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 3</span><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 4</span><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">silly-demo</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 5</span><span class="cl"><span class="w">  </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 6</span><span class="cl"><span class="w">    </span><span class="nt">app.kubernetes.io/name</span><span class="p">:</span><span class="w"> </span><span class="l">silly-demo</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 7</span><span class="cl"><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 8</span><span class="cl"><span class="w">  </span><span class="nt">replicas</span><span class="p">:</span><span class="w"> </span><span class="m">3</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 9</span><span class="cl"><span class="w">  </span><span class="nt">selector</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">10</span><span class="cl"><span class="w">    </span><span class="nt">matchLabels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">11</span><span class="cl"><span class="w">      </span><span class="nt">app.kubernetes.io/name</span><span class="p">:</span><span class="w"> </span><span class="l">silly-demo</span><span class="w">
</span></span></span><span class="line"><span class="ln">12</span><span class="cl"><span class="w">  </span><span class="nt">template</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">13</span><span class="cl"><span class="w">    </span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">14</span><span class="cl"><span class="w">      </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">15</span><span class="cl"><span class="w">        </span><span class="nt">app.kubernetes.io/name</span><span class="p">:</span><span class="w"> </span><span class="l">silly-demo</span><span class="w">
</span></span></span><span class="line"><span class="ln">16</span><span class="cl"><span class="w">    </span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">17</span><span class="cl"><span class="w">      </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">18</span><span class="cl"><span class="w">        </span>- <span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">ghcr.io/vfarcic/silly-demo:1.4.115</span><span class="w">
</span></span></span><span class="line"><span class="ln">19</span><span class="cl"><span class="w">          </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">silly-demo</span><span class="w">
</span></span></span><span class="line"><span class="ln">20</span><span class="cl"><span class="w">          </span><span class="nt">ports</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">21</span><span class="cl"><span class="w">            </span>- <span class="nt">containerPort</span><span class="p">:</span><span class="w"> </span><span class="m">8080</span><span class="w">    
</span></span></span><span class="line"><span class="ln">22</span><span class="cl"><span class="w">          </span><span class="nt">readinessProbe</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">23</span><span class="cl"><span class="w">            </span><span class="nt">httpGet</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">24</span><span class="cl"><span class="w">              </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l">/</span><span class="w">
</span></span></span><span class="line"><span class="ln">25</span><span class="cl"><span class="w">              </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="m">8080</span><span class="w">
</span></span></span><span class="line"><span class="ln">26</span><span class="cl"><span class="w">          </span><span class="nt">resources</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">27</span><span class="cl"><span class="w">            </span><span class="nt">limits</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">28</span><span class="cl"><span class="w">              </span><span class="nt">cpu</span><span class="p">:</span><span class="w"> </span><span class="l">250m</span><span class="w">
</span></span></span><span class="line"><span class="ln">29</span><span class="cl"><span class="w">              </span><span class="nt">memory</span><span class="p">:</span><span class="w"> </span><span class="l">256Mi</span><span class="w">
</span></span></span><span class="line"><span class="ln">30</span><span class="cl"><span class="w">            </span><span class="nt">requests</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">31</span><span class="cl"><span class="w">              </span><span class="nt">cpu</span><span class="p">:</span><span class="w"> </span><span class="l">125m</span><span class="w">
</span></span></span><span class="line"><span class="ln">32</span><span class="cl"><span class="w">              </span><span class="nt">memory</span><span class="p">:</span><span class="w"> </span><span class="l">128Mi</span><span class="w">
</span></span></span></code></pre></div><p>This is a <code>ReplicaSet</code> very similar to the definition of the Pod we explored earlier. The <code>containers</code> section is exactly the same. The difference, however, is that the <code>spec</code> is now part of a <code>template</code>. We are telling ReplicaSet how to create Pods rather than what the Pods are. ReplicaSet is a controller that ensures that Pods we want are the Pods that will run, forever and ever.</p>
<p>A second difference is that, this time, we have an option to specify the number of <code>replicas</code>. So, we are not only saying &quot;This is the template to create Pods&quot; but also &quot;This is the number of Pods I want. No more, no less.&quot;</p>
<p>Let's apply that ReplicaSet.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">kubectl --namespace a-team apply --filename replicaset/base.yaml
</span></span></code></pre></div><p>The easiest way to see what's happened is through the <code>kubectl tree</code> plugin, so let's use it.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">kubectl tree --namespace a-team replicaset silly-demo
</span></span></code></pre></div><p>The output is as follows.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln">1</span><span class="cl">NAMESPACE NAME                   READY REASON AGE
</span></span><span class="line"><span class="ln">2</span><span class="cl">a-team    ReplicaSet/silly-demo  -            23s
</span></span><span class="line"><span class="ln">3</span><span class="cl">a-team    ‚îú‚îÄPod/silly-demo-7z7zt True         23s
</span></span><span class="line"><span class="ln">4</span><span class="cl">a-team    ‚îú‚îÄPod/silly-demo-hj4k2 True         23s
</span></span><span class="line"><span class="ln">5</span><span class="cl">a-team    ‚îî‚îÄPod/silly-demo-npgb6 True         23s
</span></span></code></pre></div><p>kubectl tree plugin allows us to explore ownership relationships between Kubernetes resource. In this case, we can see that the <code>ReplicaSet</code> created three <code>Pods</code> and it now owns them. It's responsible for them. It's making sure that the &quot;contract&quot; is maintained meaning that it is ensuring that three Pods based on the template we specified are always up-and-running.</p>
<p>
  <figure>
  <picture>

    
      
        
        
        
        
        
        
    <img
      loading="lazy"
      decoding="async"
      alt=""
      
        class="image_figure image_internal image_processed"
        width="720"
        height="742"
        src="/post/workloads/diag-02.png"
      
      
    />

    </picture>
</figure>
</p>
<p>All in all, we sent a request to the Kube API to apply a ReplicaSet . Since that ReplicaSet did not exist, Kubernetes created it . The ReplicaSet controller detected a discrepancy between the desired and the actual state. We said that we want to have three Pods , and there were none owner by that ReplicaSet. Hence, the controller created three Pods  based on the template we defined.</p>
<p>We can confirm that is indeed the case by deleting one of those Pods,</p>
<p><em>Replace <code>[...]</code> with the name of one of the Pods (e.g., <code>silly-demo-7z7zt</code>)</em></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">kubectl --namespace a-team delete pod <span class="o">[</span>...<span class="o">]</span>
</span></span></code></pre></div><p>...and retrieving the ReplicaSet and the Pods it owns with <code>kubectl tree</code>.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">kubectl tree --namespace a-team replicaset silly-demo
</span></span></code></pre></div><p>The can see that there are three Pods, one of them being created a moment ago.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln">1</span><span class="cl">NAMESPACE NAME                   READY REASON AGE 
</span></span><span class="line"><span class="ln">2</span><span class="cl">a-team    ReplicaSet/silly-demo  -            103s
</span></span><span class="line"><span class="ln">3</span><span class="cl">a-team    ‚îú‚îÄPod/silly-demo-hj4k2 True         103s
</span></span><span class="line"><span class="ln">4</span><span class="cl">a-team    ‚îú‚îÄPod/silly-demo-jw6p5 True         13s 
</span></span><span class="line"><span class="ln">5</span><span class="cl">a-team    ‚îî‚îÄPod/silly-demo-npgb6 True         103s
</span></span></code></pre></div><p>That's the fulfilment of the &quot;contract&quot; in action. ReplicaSet manages Pods by continuously watching their state and reacting if it differ from what was specified. As a result, it created a new Pod to replace the one we deleted.</p>
<p>So, when we removed the Pods , the ReplicaSet detected the discrepancy between what we want and what something is, and created three new Pods .</p>
<p>Similarly, we can use it to scale up and down.</p>
<p>Let's take a look at a diff between the manifest we applied and a slightly modified version.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">diff replicaset/base.yaml replicaset/replicas.yaml
</span></span></code></pre></div><p>The output is as follows.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln">1</span><span class="cl">8c8
</span></span><span class="line"><span class="ln">2</span><span class="cl">&lt;   replicas: 3
</span></span><span class="line"><span class="ln">3</span><span class="cl">---
</span></span><span class="line"><span class="ln">4</span><span class="cl">&gt;   replicas: 5
</span></span></code></pre></div><p>We can see that the only difference is that the new manifest has <code>5</code> instead of <code>3</code> replicas.</p>
<p>You can probably guess what will happen if we apply it, but let's do it anyways.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">kubectl --namespace a-team apply <span class="se">\
</span></span></span><span class="line"><span class="ln">2</span><span class="cl"><span class="se"></span>    --filename replicaset/replicas.yaml
</span></span><span class="line"><span class="ln">3</span><span class="cl">
</span></span><span class="line"><span class="ln">4</span><span class="cl">kubectl tree --namespace a-team replicaset silly-demo
</span></span></code></pre></div><p>The output is as follows.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln">1</span><span class="cl">NAMESPACE NAME                   READY REASON AGE  
</span></span><span class="line"><span class="ln">2</span><span class="cl">a-team    ReplicaSet/silly-demo  -            2m32s
</span></span><span class="line"><span class="ln">3</span><span class="cl">a-team    ‚îú‚îÄPod/silly-demo-gx742 True         5s   
</span></span><span class="line"><span class="ln">4</span><span class="cl">a-team    ‚îú‚îÄPod/silly-demo-hj4k2 True         2m32s
</span></span><span class="line"><span class="ln">5</span><span class="cl">a-team    ‚îú‚îÄPod/silly-demo-jw6p5 True         62s  
</span></span><span class="line"><span class="ln">6</span><span class="cl">a-team    ‚îú‚îÄPod/silly-demo-npgb6 True         2m32s
</span></span><span class="line"><span class="ln">7</span><span class="cl">a-team    ‚îî‚îÄPod/silly-demo-wj52t True         5s   
</span></span></code></pre></div><p>This time, we can see that there are five Pods managed by the <code>ReplicaSet</code>.</p>
<p>We changed the number of replicas in the manifest  and sent it to Kube API  which resulted in the updated ReplicaSet running in the cluster . That ReplicaSet noticed that the desired state of five replicas is not the same as the actual state of three, and created two new Pods .</p>
<p>Now, there is one important note here.</p>
<p>ReplicaSet ensures that the desired state specified in the spec is always the same as the actual state, except for the template. Template is used to create new Pods, and nothing else. ReplicaSet does not ensure that the state of the Pods created with the template is always correct.</p>
<p>We can demonstrate that with a modified version of the manifest, so let's take a look at the diff.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">diff replicaset/replicas.yaml replicaset/image.yaml
</span></span></code></pre></div><p>The output is as follows.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln">1</span><span class="cl">18c18
</span></span><span class="line"><span class="ln">2</span><span class="cl">&lt;         - image: ghcr.io/vfarcic/silly-demo:1.4.115
</span></span><span class="line"><span class="ln">3</span><span class="cl">---
</span></span><span class="line"><span class="ln">4</span><span class="cl">&gt;         - image: ghcr.io/vfarcic/silly-demo:1.4.116
</span></span></code></pre></div><p>We can see that the tag of the image changed from <code>115</code> to <code>116</code>.</p>
<p>Let's see what happens if we apply that manifest,...</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">kubectl --namespace a-team apply --filename replicaset/image.yaml
</span></span></code></pre></div><p>...and retrieve the dependency tree of the ReplicaSet.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">kubectl tree --namespace a-team replicaset silly-demo
</span></span></code></pre></div><p>The output is as follows.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln">1</span><span class="cl">NAMESPACE NAME                   READY REASON AGE  
</span></span><span class="line"><span class="ln">2</span><span class="cl">a-team    ReplicaSet/silly-demo  -            3m58s
</span></span><span class="line"><span class="ln">3</span><span class="cl">a-team    ‚îú‚îÄPod/silly-demo-gx742 True         91s  
</span></span><span class="line"><span class="ln">4</span><span class="cl">a-team    ‚îú‚îÄPod/silly-demo-hj4k2 True         3m58s
</span></span><span class="line"><span class="ln">5</span><span class="cl">a-team    ‚îú‚îÄPod/silly-demo-jw6p5 True         2m28s
</span></span><span class="line"><span class="ln">6</span><span class="cl">a-team    ‚îú‚îÄPod/silly-demo-npgb6 True         3m58s
</span></span><span class="line"><span class="ln">7</span><span class="cl">a-team    ‚îî‚îÄPod/silly-demo-wj52t True         91s  
</span></span></code></pre></div><p>Judging by the <code>AGE</code>, we can see that no new Pods were created. The ReplicaSet did nothing because we did not modify the specification itself but the template used to create Pods.</p>
<p>We can confirm that even further by retrieving the YAML specification of the Pods running in the cluster.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">kubectl --namespace a-team get pods --output yaml <span class="p">|</span> yq .
</span></span></code></pre></div><p>The output is as follows (truncated for brevity).</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="ln">1</span><span class="cl"><span class="nn">...</span><span class="w">
</span></span></span><span class="line"><span class="ln">2</span><span class="cl"><span class="w">  </span>- <span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span></span></span><span class="line"><span class="ln">3</span><span class="cl"><span class="w">    </span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Pod</span><span class="w">
</span></span></span><span class="line"><span class="ln">4</span><span class="cl"><span class="w">    </span><span class="l">...</span><span class="w">
</span></span></span><span class="line"><span class="ln">5</span><span class="cl"><span class="w">    </span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">6</span><span class="cl"><span class="w">      </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">7</span><span class="cl"><span class="w">        </span>- <span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">ghcr.io/vfarcic/silly-demo:1.4.115</span><span class="w">
</span></span></span><span class="line"><span class="ln">8</span><span class="cl"><span class="w">          </span><span class="l">...</span><span class="w">
</span></span></span></code></pre></div><p>We can see that the image is still <code>115</code>. The changes we made to the template were not applied since, as I already mentioned, template is not used to manage the state of the Pods but only to create new Pods.</p>
<p>Now, try to guess what will happen if we delete all the Pods managed by that ReplicaSet,...</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">kubectl --namespace a-team delete pods <span class="se">\
</span></span></span><span class="line"><span class="ln">2</span><span class="cl"><span class="se"></span>    --selector app.kubernetes.io/name<span class="o">=</span>silly-demo
</span></span></code></pre></div><p>...and retrieve all the dependencies of the ReplicaSet.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">kubectl tree --namespace a-team replicaset silly-demo
</span></span></code></pre></div><p>The output is as follows.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln">1</span><span class="cl">NAMESPACE NAME                   READY REASON AGE
</span></span><span class="line"><span class="ln">2</span><span class="cl">a-team    ReplicaSet/silly-demo  -            7m41s
</span></span><span class="line"><span class="ln">3</span><span class="cl">a-team    ‚îú‚îÄPod/silly-demo-7fhpn True         39s
</span></span><span class="line"><span class="ln">4</span><span class="cl">a-team    ‚îú‚îÄPod/silly-demo-hcrkt True         39s
</span></span><span class="line"><span class="ln">5</span><span class="cl">a-team    ‚îú‚îÄPod/silly-demo-q2ngj True         39s
</span></span><span class="line"><span class="ln">6</span><span class="cl">a-team    ‚îú‚îÄPod/silly-demo-stlvn True         39s
</span></span><span class="line"><span class="ln">7</span><span class="cl">a-team    ‚îî‚îÄPod/silly-demo-zxwxj True         39s
</span></span></code></pre></div><p>We can see that new Pods were created. That was to be expected since, as you know, we made a contract that the number of replicas should always be five. We already saw that and the reason for deleting the Pods is not to demonstrate that ReplicaSet always maintains the spec, but what happens with changes to the template.</p>
<p>Let's retrieve YAML spec of the Pods in the cluster one more time.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">kubectl --namespace a-team get pods --output yaml <span class="p">|</span> yq .
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="ln">1</span><span class="cl"><span class="nn">...</span><span class="w">
</span></span></span><span class="line"><span class="ln">2</span><span class="cl"><span class="w">  </span>- <span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span></span></span><span class="line"><span class="ln">3</span><span class="cl"><span class="w">    </span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Pod</span><span class="w">
</span></span></span><span class="line"><span class="ln">4</span><span class="cl"><span class="w">    </span><span class="l">...</span><span class="w">
</span></span></span><span class="line"><span class="ln">5</span><span class="cl"><span class="w">    </span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">6</span><span class="cl"><span class="w">      </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">7</span><span class="cl"><span class="w">        </span>- <span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">ghcr.io/vfarcic/silly-demo:1.4.116</span><span class="w">
</span></span></span><span class="line"><span class="ln">8</span><span class="cl"><span class="w">          </span><span class="l">...</span><span class="w">
</span></span></span></code></pre></div><p>We can see that, this time, the version is indeed set to the new one, to <code>116</code>.</p>
<p>The ReplicaSet detected that the number of running Pods differs from the number of specified Pods, and created those that were missing. It used the template to do that.</p>
<p>There's a thing though. Just as you will probably never run Pods directly, you will probably not be creating ReplicaSets either. We already saw that ReplicaSets are limited when we changed the version of the image in the template. We had to delete the Pods for that change to be applied. That's, obviously, not ideal. We should have used Deployments instead, and we will, but only after we delete the ReplicaSet we created.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">kubectl --namespace a-team delete <span class="se">\
</span></span></span><span class="line"><span class="ln">2</span><span class="cl"><span class="se"></span>    --filename replicaset/image.yaml
</span></span></code></pre></div><p>Here's another lesson. When we delete a Kubernetes resource, the controller behind it makes sure that all the resources that might have been managed by it are removed as well. Since the ReplicaSet was managing Pods, they should be deleted as well.</p>
<p>Let's double check that.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">kubectl --namespace a-team get all
</span></span></code></pre></div><p>The output is as follows.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln">1</span><span class="cl">No resources found in a-team namespace.
</span></span></code></pre></div><p>It's all gone. There is nothing. There is no ReplicaSet and there are no Pods.</p>
<p>We deleted the ReplicaSet  which, before dissapearing completely, made sure that the dependant resources were deleted as well. In this case, those dependent resources were the Pods it created and managed . Only after the ReplicaSet controller deleted all the Pods it owned, it removed itself from the system .</p>
<p>With everything gone, we can take a look at Deployments.</p>
<h2 id="deployments-in-kubernetes">Deployments in Kubernetes</h2>
<p>Deployments are almost the same as ReplicaSets, at least when defining them is concerned.</p>
<p>Let's take a diff between the two I prepared.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">diff replicaset/image.yaml deployment/base.yaml
</span></span></code></pre></div><p>The output is as follows.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln"> 1</span><span class="cl">2c2
</span></span><span class="line"><span class="ln"> 2</span><span class="cl">&lt; kind: ReplicaSet
</span></span><span class="line"><span class="ln"> 3</span><span class="cl">---
</span></span><span class="line"><span class="ln"> 4</span><span class="cl">&gt; kind: Deployment
</span></span><span class="line"><span class="ln"> 5</span><span class="cl">8a9,13
</span></span><span class="line"><span class="ln"> 6</span><span class="cl">&gt;   minReadySeconds: 10
</span></span><span class="line"><span class="ln"> 7</span><span class="cl">&gt;   strategy:
</span></span><span class="line"><span class="ln"> 8</span><span class="cl">&gt;     rollingUpdate:
</span></span><span class="line"><span class="ln"> 9</span><span class="cl">&gt;       maxUnavailable: 1
</span></span><span class="line"><span class="ln">10</span><span class="cl">&gt;       maxSurge: 1
</span></span></code></pre></div><p>We can see that the <code>kind</code> changed. That could have been the only change. I also added <code>minReadySeconds</code> and <code>strategy</code> entries, not necessarily because we needed those but, rather, because those will slow down some processes we'll explore later so that we can observe them easily.</p>
<p>Anyway... Let's apply that Deployment,...</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">kubectl --namespace a-team apply --filename deployment/base.yaml
</span></span></code></pre></div><p>...and take a look at the tree.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">kubectl tree --namespace a-team deployment silly-demo
</span></span></code></pre></div><p>The output is as follows.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln">1</span><span class="cl">NAMESPACE NAME                               READY REASON AGE
</span></span><span class="line"><span class="ln">2</span><span class="cl">a-team    Deployment/silly-demo              -            10s
</span></span><span class="line"><span class="ln">3</span><span class="cl">a-team    ‚îî‚îÄReplicaSet/silly-demo-5f76b8d84  -            10s
</span></span><span class="line"><span class="ln">4</span><span class="cl">a-team      ‚îú‚îÄPod/silly-demo-5f76b8d84-c5lvb True         10s
</span></span><span class="line"><span class="ln">5</span><span class="cl">a-team      ‚îú‚îÄPod/silly-demo-5f76b8d84-c9vkt True         10s
</span></span><span class="line"><span class="ln">6</span><span class="cl">a-team      ‚îú‚îÄPod/silly-demo-5f76b8d84-j9wgh True         10s
</span></span><span class="line"><span class="ln">7</span><span class="cl">a-team      ‚îú‚îÄPod/silly-demo-5f76b8d84-rspnv True         10s
</span></span><span class="line"><span class="ln">8</span><span class="cl">a-team      ‚îî‚îÄPod/silly-demo-5f76b8d84-vchgz True         10s
</span></span></code></pre></div><p>On the first look, creating that <code>Deployment</code> seems like a waste. The end result are the same five <code>Pods</code> we would get if we created the <code>ReplicaSet</code> directly.</p>
<p>
  <figure>
  <picture>

    
      
        
        
        
        
        
        
    <img
      loading="lazy"
      decoding="async"
      alt=""
      
        class="image_figure image_internal image_processed"
        width="737"
        height="821"
        src="/post/workloads/diag-03.png"
      
      
    />

    </picture>
</figure>
</p>
<p>We sent a request to the Kube API to apply a manifest of a Deployment , a Deployment was created , and its controller created a ReplicaSet . The controller of the ReplicaSet saw that Pods are missing, so it created them .</p>
<p>Now, let's take a look at one of the things that make Deployments special. As you saw before, updating a template of a ReplicaSet does not affect existing Pods so changing the image tag did not produce the effect we wanted. Let's see what will happen if we do the same with the Deployment.</p>
<p>Here's a diff of the changes I made to the Deployment manifest.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">diff deployment/base.yaml deployment/image.yaml
</span></span></code></pre></div><p>The output is as follows.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln">1</span><span class="cl">23c23
</span></span><span class="line"><span class="ln">2</span><span class="cl">&lt;         - image: ghcr.io/vfarcic/silly-demo:1.4.116
</span></span><span class="line"><span class="ln">3</span><span class="cl">---
</span></span><span class="line"><span class="ln">4</span><span class="cl">&gt;         - image: ghcr.io/vfarcic/silly-demo:1.4.117
</span></span></code></pre></div><p>The only modification is in the <code>image</code> value which now contains tag <code>117</code>.</p>
<p>A few things will happen if we update that Deployment, so I'll execute <code>kubectl apply</code> followed with <code>kubectl tree</code> to output right away the ownership tree. Since I want us to see how it progresses, we'll use <code>viddy</code> to output the tree every second. If you're not familiar with <code>viddy</code>, it is an alternative to <code>watch</code>.</p>
<p>Anyways... Here it goes...</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">kubectl --namespace a-team apply <span class="se">\
</span></span></span><span class="line"><span class="ln">2</span><span class="cl"><span class="se"></span>    --filename deployment/image.yaml <span class="se">\
</span></span></span><span class="line"><span class="ln">3</span><span class="cl"><span class="se"></span>    <span class="o">&amp;&amp;</span> viddy kubectl tree --namespace a-team <span class="se">\
</span></span></span><span class="line"><span class="ln">4</span><span class="cl"><span class="se"></span>    deployment silly-demo
</span></span></code></pre></div><p>The output is as follows.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln"> 1</span><span class="cl">...
</span></span><span class="line"><span class="ln"> 2</span><span class="cl">NAMESPACE NAME                                READY REASON AGE
</span></span><span class="line"><span class="ln"> 3</span><span class="cl">a-team    Deployment/silly-demo               -            73s
</span></span><span class="line"><span class="ln"> 4</span><span class="cl">a-team    ‚îú‚îÄReplicaSet/silly-demo-5f76b8d84   -            73s
</span></span><span class="line"><span class="ln"> 5</span><span class="cl">a-team    ‚îÇ ‚îú‚îÄPod/silly-demo-5f76b8d84-c5lvb  True         73s
</span></span><span class="line"><span class="ln"> 6</span><span class="cl">a-team    ‚îÇ ‚îú‚îÄPod/silly-demo-5f76b8d84-c9vkt  True         73s
</span></span><span class="line"><span class="ln"> 7</span><span class="cl">a-team    ‚îÇ ‚îú‚îÄPod/silly-demo-5f76b8d84-j9wgh  True         73s
</span></span><span class="line"><span class="ln"> 8</span><span class="cl">a-team    ‚îÇ ‚îî‚îÄPod/silly-demo-5f76b8d84-rspnv  True         73s
</span></span><span class="line"><span class="ln"> 9</span><span class="cl">a-team    ‚îî‚îÄReplicaSet/silly-demo-7879f7dfd7  -            9s
</span></span><span class="line"><span class="ln">10</span><span class="cl">a-team      ‚îú‚îÄPod/silly-demo-7879f7dfd7-98758 True         9s
</span></span><span class="line"><span class="ln">11</span><span class="cl">a-team      ‚îî‚îÄPod/silly-demo-7879f7dfd7-md865 True         9s
</span></span></code></pre></div><p>Deployment created a second ReplicaSet which, initially, was set to have a single replica of a Pod that uses the new image tag. From there on, it started performing rolling updates. It started reducing the number of replicas in the old ReplicaSet and increasing the number of replicas in the new.</p>
<p>The output is as follows (cont.).</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln">1</span><span class="cl">NAMESPACE NAME                                READY REASON AGE
</span></span><span class="line"><span class="ln">2</span><span class="cl">a-team    Deployment/silly-demo               -            2m3s
</span></span><span class="line"><span class="ln">3</span><span class="cl">a-team    ‚îú‚îÄReplicaSet/silly-demo-5f76b8d84   -            2m3s
</span></span><span class="line"><span class="ln">4</span><span class="cl">a-team    ‚îî‚îÄReplicaSet/silly-demo-7879f7dfd7  -            59s
</span></span><span class="line"><span class="ln">5</span><span class="cl">a-team      ‚îú‚îÄPod/silly-demo-7879f7dfd7-98758 True         59s
</span></span><span class="line"><span class="ln">6</span><span class="cl">a-team      ‚îú‚îÄPod/silly-demo-7879f7dfd7-9jqgv True         45s
</span></span><span class="line"><span class="ln">7</span><span class="cl">a-team      ‚îú‚îÄPod/silly-demo-7879f7dfd7-dwvz9 True         31s
</span></span><span class="line"><span class="ln">8</span><span class="cl">a-team      ‚îú‚îÄPod/silly-demo-7879f7dfd7-f8lfx True         45s
</span></span><span class="line"><span class="ln">9</span><span class="cl">a-team      ‚îî‚îÄPod/silly-demo-7879f7dfd7-md865 True         59s
</span></span></code></pre></div><p>At the end of the process, the old ReplicaSet was scaled to zero replicas, and the new one, the one with the new image tag, was scaled to five replicas. That was an example of an effeortless rolling updates and is, arguably, the main reason why we use Deployments.</p>
<p><em>Stop watching by pressing <code>ctrl+c</code>.</em></p>
<p>Here's what happened.</p>
<p>We modified the manifest of the Deployment to use image tag <code>117</code>  and applied it to the Kube API . That resulted in updated Deployment  which, in turn, realized that the tag changed and created a second ReplicaSet set to have a single replica . The new ReplicaSet created a single Pod . From there on, Deployment started updating both ReplicaSets. It was reducing the number of replicas in the old one and increasing the number of replicas in the new. As a result, the old ReplicaSet started removing Pods while the new one was creating them . Eventually, all Pods ended up being managed by the new ReplicaSet while the old one ended up managing none.</p>
<p>The new version of the application was released safely and without downtime. Huray!</p>
<p>There's one more thing related to Deployments we need to explore. We need to talk about volumes since they are one of the main reasons why you might choose NOT to use Deployments.</p>
<h2 id="deployment-volumes-in-kubernetes">Deployment Volumes in Kubernetes</h2>
<p>So far, we established that we should neither use Pods nor ReplicaSets. They are important building blocks and understanding them is important, but we can safely focus on Deployments which will create and manage those for us.</p>
<p>But, depending on the type of the application we have, Deployments might or might not be a good choice. The main reason why we might use them or discard them lies in how they manage volumes which are, most of the time, external storage.</p>
<p>Let's take a look at yet another example.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">cat deployment/volume.yaml
</span></span></code></pre></div><p>The output is as follows.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="ln"> 1</span><span class="cl"><span class="nn">---</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 2</span><span class="cl"><span class="w"></span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 3</span><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">PersistentVolumeClaim</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 4</span><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 5</span><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">silly-claim</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 6</span><span class="cl"><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 7</span><span class="cl"><span class="w">  </span><span class="nt">accessModes</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 8</span><span class="cl"><span class="w">    </span>- <span class="l">ReadWriteOnce</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 9</span><span class="cl"><span class="w">  </span><span class="nt">resources</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">10</span><span class="cl"><span class="w">    </span><span class="nt">requests</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">11</span><span class="cl"><span class="w">      </span><span class="nt">storage</span><span class="p">:</span><span class="w"> </span><span class="l">1Gi</span><span class="w">
</span></span></span><span class="line"><span class="ln">12</span><span class="cl"><span class="w"></span><span class="nn">---</span><span class="w">
</span></span></span><span class="line"><span class="ln">13</span><span class="cl"><span class="w"></span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">apps/v1</span><span class="w">
</span></span></span><span class="line"><span class="ln">14</span><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Deployment</span><span class="w">
</span></span></span><span class="line"><span class="ln">15</span><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">16</span><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">silly-demo</span><span class="w">
</span></span></span><span class="line"><span class="ln">17</span><span class="cl"><span class="w">  </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">18</span><span class="cl"><span class="w">    </span><span class="nt">app.kubernetes.io/name</span><span class="p">:</span><span class="w"> </span><span class="l">silly-demo</span><span class="w">
</span></span></span><span class="line"><span class="ln">19</span><span class="cl"><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">20</span><span class="cl"><span class="w">  </span><span class="nt">replicas</span><span class="p">:</span><span class="w"> </span><span class="m">5</span><span class="w">
</span></span></span><span class="line"><span class="ln">21</span><span class="cl"><span class="w">  </span><span class="nt">minReadySeconds</span><span class="p">:</span><span class="w"> </span><span class="m">10</span><span class="w">
</span></span></span><span class="line"><span class="ln">22</span><span class="cl"><span class="w">  </span><span class="nt">strategy</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">23</span><span class="cl"><span class="w">    </span><span class="nt">rollingUpdate</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">24</span><span class="cl"><span class="w">      </span><span class="nt">maxUnavailable</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span></span></span><span class="line"><span class="ln">25</span><span class="cl"><span class="w">      </span><span class="nt">maxSurge</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span></span></span><span class="line"><span class="ln">26</span><span class="cl"><span class="w">  </span><span class="nt">selector</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">27</span><span class="cl"><span class="w">    </span><span class="nt">matchLabels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">28</span><span class="cl"><span class="w">      </span><span class="nt">app.kubernetes.io/name</span><span class="p">:</span><span class="w"> </span><span class="l">silly-demo</span><span class="w">
</span></span></span><span class="line"><span class="ln">29</span><span class="cl"><span class="w">  </span><span class="nt">template</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">30</span><span class="cl"><span class="w">    </span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">31</span><span class="cl"><span class="w">      </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">32</span><span class="cl"><span class="w">        </span><span class="nt">app.kubernetes.io/name</span><span class="p">:</span><span class="w"> </span><span class="l">silly-demo</span><span class="w">
</span></span></span><span class="line"><span class="ln">33</span><span class="cl"><span class="w">    </span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">34</span><span class="cl"><span class="w">      </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">35</span><span class="cl"><span class="w">        </span>- <span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">ghcr.io/vfarcic/silly-demo:1.4.117</span><span class="w">
</span></span></span><span class="line"><span class="ln">36</span><span class="cl"><span class="w">          </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">silly-demo</span><span class="w">
</span></span></span><span class="line"><span class="ln">37</span><span class="cl"><span class="w">          </span><span class="nt">ports</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">38</span><span class="cl"><span class="w">            </span>- <span class="nt">containerPort</span><span class="p">:</span><span class="w"> </span><span class="m">8080</span><span class="w">    
</span></span></span><span class="line"><span class="ln">39</span><span class="cl"><span class="w">          </span><span class="nt">readinessProbe</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">40</span><span class="cl"><span class="w">            </span><span class="nt">httpGet</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">41</span><span class="cl"><span class="w">              </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l">/</span><span class="w">
</span></span></span><span class="line"><span class="ln">42</span><span class="cl"><span class="w">              </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="m">8080</span><span class="w">
</span></span></span><span class="line"><span class="ln">43</span><span class="cl"><span class="w">          </span><span class="nt">resources</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">44</span><span class="cl"><span class="w">            </span><span class="nt">limits</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">45</span><span class="cl"><span class="w">              </span><span class="nt">cpu</span><span class="p">:</span><span class="w"> </span><span class="l">250m</span><span class="w">
</span></span></span><span class="line"><span class="ln">46</span><span class="cl"><span class="w">              </span><span class="nt">memory</span><span class="p">:</span><span class="w"> </span><span class="l">256Mi</span><span class="w">
</span></span></span><span class="line"><span class="ln">47</span><span class="cl"><span class="w">            </span><span class="nt">requests</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">48</span><span class="cl"><span class="w">              </span><span class="nt">cpu</span><span class="p">:</span><span class="w"> </span><span class="l">125m</span><span class="w">
</span></span></span><span class="line"><span class="ln">49</span><span class="cl"><span class="w">              </span><span class="nt">memory</span><span class="p">:</span><span class="w"> </span><span class="l">128Mi</span><span class="w">
</span></span></span><span class="line"><span class="ln">50</span><span class="cl"><span class="w">          </span><span class="nt">volumeMounts</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">51</span><span class="cl"><span class="w">          </span>- <span class="nt">mountPath</span><span class="p">:</span><span class="w"> </span><span class="l">/cache</span><span class="w">
</span></span></span><span class="line"><span class="ln">52</span><span class="cl"><span class="w">            </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">silly-cache</span><span class="w">
</span></span></span><span class="line"><span class="ln">53</span><span class="cl"><span class="w">      </span><span class="nt">volumes</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">54</span><span class="cl"><span class="w">        </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">silly-cache</span><span class="w">
</span></span></span><span class="line"><span class="ln">55</span><span class="cl"><span class="w">          </span><span class="nt">persistentVolumeClaim</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">56</span><span class="cl"><span class="w">            </span><span class="nt">claimName</span><span class="p">:</span><span class="w"> </span><span class="l">silly-claim</span><span class="w">
</span></span></span></code></pre></div><p>This manifest defines two resources.</p>
<p>The first one is a <code>PersistentVolumeClaim</code>. I'll explore volumes in one of the upcoming videos. For now, what matters, is that <code>PersistentVolumeClaim</code> is a way for us to claim a volume, to request storage that can be attacted to containers in a Pod.</p>
<p>Further down, we have a modified version of the <code>Deployment</code> we used earlier.</p>
<p>At the very bottom of it is the list of <code>volumes</code> we'd like to have. There's only one called <code>silly-cache</code> which references the <code>persistentVolumeClaim</code> named <code>silly-claim</code>.</p>
<p>Inside the <code>containers</code> section we are mounting the <code>silly-cache</code> volume into the <code>/cache</code> directory inside the container.</p>
<p>As a result, all <code>5</code> replicas of our application should have external storage mounted.</p>
<p>Here's a question for you. How many volumes do you think will be created for those five replicas?</p>
<p>Do not answer that question aloud. It's not a good idea to talk to your monitor. Keep the number to yourself while we take a look at the result.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">kubectl --namespace a-team apply <span class="se">\
</span></span></span><span class="line"><span class="ln">2</span><span class="cl"><span class="se"></span>    --filename deployment/volume.yaml
</span></span></code></pre></div><p>The output is as follows.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln">1</span><span class="cl">persistentvolumeclaim/silly-claim created
</span></span><span class="line"><span class="ln">2</span><span class="cl">deployment.apps/silly-demo configured
</span></span></code></pre></div><p>Let's wait for a few moments until rolling updates are finished.... and take a look at the <code>pods</code> and <code>persistentvolumes</code> that were created.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">kubectl --namespace a-team get pods,persistentvolumes
</span></span></code></pre></div><p>The output is as follows.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln">1</span><span class="cl">NAME                            READY STATUS  RESTARTS AGE
</span></span><span class="line"><span class="ln">2</span><span class="cl">pod/silly-demo-77fb46fcfc-5bqw5 1/1   Running 0        27s
</span></span><span class="line"><span class="ln">3</span><span class="cl">pod/silly-demo-77fb46fcfc-5lgdf 1/1   Running 0        27s
</span></span><span class="line"><span class="ln">4</span><span class="cl">pod/silly-demo-77fb46fcfc-cdtrl 1/1   Running 0        11s
</span></span><span class="line"><span class="ln">5</span><span class="cl">pod/silly-demo-77fb46fcfc-hpr24 1/1   Running 0        11s
</span></span><span class="line"><span class="ln">6</span><span class="cl">pod/silly-demo-7879f7dfd7-98758 1/1   Running 0        1s
</span></span><span class="line"><span class="ln">7</span><span class="cl">
</span></span><span class="line"><span class="ln">8</span><span class="cl">NAME                                                      CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM              STORAGECLASS VOLUMEATTRIBUTESCLASS REASON AGE
</span></span><span class="line"><span class="ln">9</span><span class="cl">persistentvolume/pvc-903d6f48-bb49-4c77-995f-b4ddd773868f 1Gi      RWO          Delete         Bound  a-team/silly-claim standard     &lt;unset&gt;                      23s
</span></span></code></pre></div><p>As expected, there are five Pods. If you see more, you were inpatient and did not wait until rolling updates finished.</p>
<p>The number of Pods does not matter right now. What does matter is that there is only one <code>persistentvolume</code>. All the replicas of the application, the Pods, got the same volume attached. They are all sharing the same storage.</p>
<img src="diag-04.png" style="width:50%; float:right; padding: 10px">
<p>So, we sent a request to Kube API to apply a PersistentVolumeClaim and a Deployment  so those were created or updated inside the cluster . The Deployment itself created a ReplicaSet  which created five Pods . Since the Pods themselves ware instructed, through the template in the Deployment, to use the claim to request a volume, a PersistentVolume was created  and attached to all the Pods .</p>
<p>Now, depending on the type of the application we're using, that might be just what we want, or unacceptable. As a rule of thumb, stateless applications should be managed through Deployments. On the other hand, stateful applications tend to need separate storage for each replicas as a way to avoid potential issues when writing files to disk. Hence, we need to look for a different way to run stateful apps.</p>
<p>We'll do that right after we destroy the deployment and the volume we just created.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">kubectl --namespace a-team delete <span class="se">\
</span></span></span><span class="line"><span class="ln">2</span><span class="cl"><span class="se"></span>    --filename deployment/volume.yaml
</span></span></code></pre></div><h2 id="statefulsets-in-kubernetes">StatefulSets in Kubernetes</h2>
<p>StatefulSets are similar to Deployments, at least in the way we define them.</p>
<p>Here's an example.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">cat statefulset/base.yaml
</span></span></code></pre></div><p>The output is as follows.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="ln"> 1</span><span class="cl"><span class="nn">---</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 2</span><span class="cl"><span class="w"></span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">apps/v1</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 3</span><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">StatefulSet</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 4</span><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 5</span><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">silly-demo</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 6</span><span class="cl"><span class="w">  </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 7</span><span class="cl"><span class="w">    </span><span class="nt">app.kubernetes.io/name</span><span class="p">:</span><span class="w"> </span><span class="l">silly-demo</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 8</span><span class="cl"><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 9</span><span class="cl"><span class="w">  </span><span class="nt">replicas</span><span class="p">:</span><span class="w"> </span><span class="m">2</span><span class="w">
</span></span></span><span class="line"><span class="ln">10</span><span class="cl"><span class="w">  </span><span class="nt">minReadySeconds</span><span class="p">:</span><span class="w"> </span><span class="m">10</span><span class="w">
</span></span></span><span class="line"><span class="ln">11</span><span class="cl"><span class="w">  </span><span class="nt">updateStrategy</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">12</span><span class="cl"><span class="w">    </span><span class="nt">rollingUpdate</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">13</span><span class="cl"><span class="w">      </span><span class="nt">maxUnavailable</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span></span></span><span class="line"><span class="ln">14</span><span class="cl"><span class="w">  </span><span class="nt">selector</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">15</span><span class="cl"><span class="w">    </span><span class="nt">matchLabels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">16</span><span class="cl"><span class="w">      </span><span class="nt">app.kubernetes.io/name</span><span class="p">:</span><span class="w"> </span><span class="l">silly-demo</span><span class="w">
</span></span></span><span class="line"><span class="ln">17</span><span class="cl"><span class="w">  </span><span class="nt">template</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">18</span><span class="cl"><span class="w">    </span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">19</span><span class="cl"><span class="w">      </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">20</span><span class="cl"><span class="w">        </span><span class="nt">app.kubernetes.io/name</span><span class="p">:</span><span class="w"> </span><span class="l">silly-demo</span><span class="w">
</span></span></span><span class="line"><span class="ln">21</span><span class="cl"><span class="w">    </span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">22</span><span class="cl"><span class="w">      </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">23</span><span class="cl"><span class="w">        </span>- <span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">ghcr.io/vfarcic/silly-demo:1.4.117</span><span class="w">
</span></span></span><span class="line"><span class="ln">24</span><span class="cl"><span class="w">          </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">silly-demo</span><span class="w">
</span></span></span><span class="line"><span class="ln">25</span><span class="cl"><span class="w">          </span><span class="nt">ports</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">26</span><span class="cl"><span class="w">            </span>- <span class="nt">containerPort</span><span class="p">:</span><span class="w"> </span><span class="m">8080</span><span class="w">    
</span></span></span><span class="line"><span class="ln">27</span><span class="cl"><span class="w">          </span><span class="nt">readinessProbe</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">28</span><span class="cl"><span class="w">            </span><span class="nt">httpGet</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">29</span><span class="cl"><span class="w">              </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l">/</span><span class="w">
</span></span></span><span class="line"><span class="ln">30</span><span class="cl"><span class="w">              </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="m">8080</span><span class="w">
</span></span></span><span class="line"><span class="ln">31</span><span class="cl"><span class="w">          </span><span class="nt">resources</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">32</span><span class="cl"><span class="w">            </span><span class="nt">limits</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">33</span><span class="cl"><span class="w">              </span><span class="nt">cpu</span><span class="p">:</span><span class="w"> </span><span class="l">250m</span><span class="w">
</span></span></span><span class="line"><span class="ln">34</span><span class="cl"><span class="w">              </span><span class="nt">memory</span><span class="p">:</span><span class="w"> </span><span class="l">256Mi</span><span class="w">
</span></span></span><span class="line"><span class="ln">35</span><span class="cl"><span class="w">            </span><span class="nt">requests</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">36</span><span class="cl"><span class="w">              </span><span class="nt">cpu</span><span class="p">:</span><span class="w"> </span><span class="l">125m</span><span class="w">
</span></span></span><span class="line"><span class="ln">37</span><span class="cl"><span class="w">              </span><span class="nt">memory</span><span class="p">:</span><span class="w"> </span><span class="l">128Mi</span><span class="w">
</span></span></span><span class="line"><span class="ln">38</span><span class="cl"><span class="w">          </span><span class="nt">volumeMounts</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">39</span><span class="cl"><span class="w">          </span>- <span class="nt">mountPath</span><span class="p">:</span><span class="w"> </span><span class="l">/cache</span><span class="w">
</span></span></span><span class="line"><span class="ln">40</span><span class="cl"><span class="w">            </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">silly-claim</span><span class="w">
</span></span></span><span class="line"><span class="ln">41</span><span class="cl"><span class="w">  </span><span class="nt">volumeClaimTemplates</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">42</span><span class="cl"><span class="w">    </span>- <span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span></span></span><span class="line"><span class="ln">43</span><span class="cl"><span class="w">      </span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">PersistentVolumeClaim</span><span class="w">
</span></span></span><span class="line"><span class="ln">44</span><span class="cl"><span class="w">      </span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">45</span><span class="cl"><span class="w">        </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">silly-claim</span><span class="w">
</span></span></span><span class="line"><span class="ln">46</span><span class="cl"><span class="w">      </span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">47</span><span class="cl"><span class="w">        </span><span class="nt">accessModes</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">48</span><span class="cl"><span class="w">          </span>- <span class="l">ReadWriteOnce</span><span class="w">
</span></span></span><span class="line"><span class="ln">49</span><span class="cl"><span class="w">        </span><span class="nt">resources</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">50</span><span class="cl"><span class="w">          </span><span class="nt">requests</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">51</span><span class="cl"><span class="w">            </span><span class="nt">storage</span><span class="p">:</span><span class="w"> </span><span class="l">1Gi</span><span class="w">
</span></span></span></code></pre></div><p>On the first look, this is almost the same as the Deployment we used earlier, with three notable differences.</p>
<p>First of all, there is no need to define a PersistentVolumeClaim. We'll see why is that so.</p>
<p>Next is the obvious one with <code>kind</code> being set to <code>StatefulSet</code>.</p>
<p>Finally, the most important difference is in the way StatefulSets deal with volumes. While Deployments specify which volume claims to use, StatefulSets define <code>volumeClaimTemplates</code>. That's similar to how ReplicaSets contain Pod templates that allow them to create Pods they need. Similarly, StatefulSets have <code>volumeClaimTemplates</code> that create volume claims for each replica. In this case, we have a single claim template that is essentially the same as the <code>PersistentVolumeClaim</code> we had as a separate resource in the manifest with the Deployment.</p>
<p>What matters for now, is that StatefulSets know how to create PersistentVolumeClaims and that enables them to treat volumes in a very different way from Deployments.</p>
<p>Let's see it in action by applying the StatefulSet,...</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">kubectl --namespace a-team apply --filename statefulset/base.yaml
</span></span></code></pre></div><p>...and watching the <code>tree</code>.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">viddy kubectl tree --namespace a-team statefulset silly-demo
</span></span></code></pre></div><p>Before we get back to volumes, there is one important thing we can observe.</p>
<p>The names of the Pods are, this time, predictable. We specified that we want two replicas of <code>silly-demo</code>. Unlike with Deployments the names are predictable and the order how Pods are created and destroyed are predictable as well.</p>
<p>The output is as follows.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln">1</span><span class="cl">NAMESPACE NAME                                       READY REASON AGE            
</span></span><span class="line"><span class="ln">2</span><span class="cl">a-team    StatefulSet/silly-demo                     -            9s            
</span></span><span class="line"><span class="ln">3</span><span class="cl">a-team    ‚îú‚îÄControllerRevision/silly-demo-6848df9f6f -            9s            
</span></span><span class="line"><span class="ln">4</span><span class="cl">a-team    ‚îî‚îÄPod/silly-demo-0                         True         9s  
</span></span></code></pre></div><p>Since we requested two replicas, StatefulSet created the frist one with the name <code>silly-demo-0</code>,...</p>
<p>The output is as follows (cont.).</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln">1</span><span class="cl">NAMESPACE NAME                                       READY REASON AGE            
</span></span><span class="line"><span class="ln">2</span><span class="cl">a-team    StatefulSet/silly-demo                     -            64s            
</span></span><span class="line"><span class="ln">3</span><span class="cl">a-team    ‚îú‚îÄControllerRevision/silly-demo-6848df9f6f -            64s            
</span></span><span class="line"><span class="ln">4</span><span class="cl">a-team    ‚îú‚îÄPod/silly-demo-0                         True         64s            
</span></span><span class="line"><span class="ln">5</span><span class="cl">a-team    ‚îî‚îÄPod/silly-demo-1                         True         44s
</span></span></code></pre></div><p>...and then the second one called <code>silly-demo-1</code>.</p>
<p><em>Stop watching by pressing <code>ctrl+c</code>.</em></p>
<p>So, the names are predictable and the order Pods are created and, as you will see soon, destroyed is predictable as well. That's important when working with stateful apps like, for example, databases.</p>
<p>Another note is that, unlike Deployments, StatefulSets do not create and manage ReplicaSets. Instead, StatefulSets manage Pods directly.</p>
<p>Let's get back Pods and PersistentVolumes.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">kubectl --namespace a-team get pods,persistentvolumes
</span></span></code></pre></div><p>The output is as follows.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln">1</span><span class="cl">NAME               READY   STATUS    RESTARTS   AGE
</span></span><span class="line"><span class="ln">2</span><span class="cl">pod/silly-demo-0   1/1     Running   0          88s
</span></span><span class="line"><span class="ln">3</span><span class="cl">pod/silly-demo-1   1/1     Running   0          68s
</span></span><span class="line"><span class="ln">4</span><span class="cl">
</span></span><span class="line"><span class="ln">5</span><span class="cl">NAME                                                      CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM                           STORAGECLASS VOLUMEATTRIBUTESCLASS REASON AGE
</span></span><span class="line"><span class="ln">6</span><span class="cl">persistentvolume/pvc-254a27c2-2c82-44bc-afb2-b95e93b3c2d5 1Gi      RWO          Delete         Bound  a-team/silly-claim-silly-demo-0 standard     &lt;unset&gt;                      85s
</span></span><span class="line"><span class="ln">7</span><span class="cl">persistentvolume/pvc-7b8eccc9-ad50-4387-b3d8-4f6664e86bc6 1Gi      RWO          Delete         Bound  a-team/silly-claim-silly-demo-1 standard     &lt;unset&gt;                      65s
</span></span></code></pre></div><p>This is the important different. This time, containers in each <code>pod</code> got a separate <code>persistentvolume</code>, a separate storage attached.</p>
<p>Here's what we did and what happened.</p>
<p>
  <figure>
  <picture>

    
      
        
        
        
        
        
        
    <img
      loading="lazy"
      decoding="async"
      alt=""
      
        class="image_figure image_internal image_processed"
        width="689"
        height="758"
        src="/post/workloads/diag-05.png"
      
      
    />

    </picture>
</figure>
</p>
<p>We sent a request to Kube API to apply a StatefulSet . Since that StatefulSet did not exist in the cluster, a new one was created . Since we specified that it should contain two replicas, two Pods were created by the StatefulSet controller . In parallel, the StatefulSet created two PersistentVolumeClaims , which claimed two volumes  and atteched one to each of the Pods .</p>
<p>Let's see what happens if, for example, we increate the number of replicas.</p>
<p>Here's the diff between the old and the new manifest.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">diff statefulset/base.yaml statefulset/replicas.yaml
</span></span></code></pre></div><p>The output is as follows.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln">1</span><span class="cl">9c9
</span></span><span class="line"><span class="ln">2</span><span class="cl">&lt;   replicas: 2
</span></span><span class="line"><span class="ln">3</span><span class="cl">---
</span></span><span class="line"><span class="ln">4</span><span class="cl">&gt;   replicas: 5
</span></span></code></pre></div><p>The only change is that the number of replicas jumped from <code>2</code> to <code>5</code>.</p>
<p>Let's apply that and watch the changes of the <code>tree</code>.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">kubectl --namespace a-team apply <span class="se">\
</span></span></span><span class="line"><span class="ln">2</span><span class="cl"><span class="se"></span>    --filename statefulset/replicas.yaml <span class="se">\
</span></span></span><span class="line"><span class="ln">3</span><span class="cl"><span class="se"></span>    <span class="o">&amp;&amp;</span> viddy kubectl tree --namespace a-team <span class="se">\
</span></span></span><span class="line"><span class="ln">4</span><span class="cl"><span class="se"></span>    statefulset silly-demo
</span></span></code></pre></div><p>The output is as follows.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln">1</span><span class="cl">NAMESPACE NAME                                       READY REASON AGE
</span></span><span class="line"><span class="ln">2</span><span class="cl">a-team    StatefulSet/silly-demo                     -            3m25s
</span></span><span class="line"><span class="ln">3</span><span class="cl">a-team    ‚îú‚îÄControllerRevision/silly-demo-6848df9f6f -            3m25s
</span></span><span class="line"><span class="ln">4</span><span class="cl">a-team    ‚îú‚îÄPod/silly-demo-0                         True         3m25s
</span></span><span class="line"><span class="ln">5</span><span class="cl">a-team    ‚îú‚îÄPod/silly-demo-1                         True         3m5s
</span></span><span class="line"><span class="ln">6</span><span class="cl">a-team    ‚îî‚îÄPod/silly-demo-2                         -            3s
</span></span></code></pre></div><p>StatefulSet continues working in an ordered and predictable manner. It started by creating the third replica (<code>silly-demo-2</code>) since two were already there. Then it created the fourth (<code>silly-demo-3</code>),...</p>
<p>The output is as follows (cont.).</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln">1</span><span class="cl">NAMESPACE NAME                                       READY REASON AGE
</span></span><span class="line"><span class="ln">2</span><span class="cl">a-team    StatefulSet/silly-demo                     -            4m5s
</span></span><span class="line"><span class="ln">3</span><span class="cl">a-team    ‚îú‚îÄControllerRevision/silly-demo-6848df9f6f -            4m5s
</span></span><span class="line"><span class="ln">4</span><span class="cl">a-team    ‚îú‚îÄPod/silly-demo-0                         True         4m5s
</span></span><span class="line"><span class="ln">5</span><span class="cl">a-team    ‚îú‚îÄPod/silly-demo-1                         True         3m45s
</span></span><span class="line"><span class="ln">6</span><span class="cl">a-team    ‚îú‚îÄPod/silly-demo-2                         True         43s
</span></span><span class="line"><span class="ln">7</span><span class="cl">a-team    ‚îú‚îÄPod/silly-demo-3                         True         23s
</span></span><span class="line"><span class="ln">8</span><span class="cl">a-team    ‚îî‚îÄPod/silly-demo-4                         -            3s
</span></span></code></pre></div><p>...and the fifth (<code>silly-demo-4</code>).</p>
<p>As you can probably guess, even though we cannot see that on the screen, it also created three new PersistentVolumeClaims which resulted in three new PersistentVolumes, one for each new Pod.</p>
<p><em>Stop watching by pressing <code>ctrl+c</code>.</em></p>
<p>Finally, just as creation of Pods is predictable by always starting from the zero indexed Pod, deletion is predicatable as well. Depending on whether we reduce the number of replicas or delete the whole StatefulSet and all the Pods it manages, deletion always starts from the one with the highest index and continues down.</p>
<p>Let's delete the StatefulSet.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">kubectl --namespace a-team delete <span class="se">\
</span></span></span><span class="line"><span class="ln">2</span><span class="cl"><span class="se"></span>    --filename statefulset/replicas.yaml
</span></span></code></pre></div><p>I'll leave it to you to observe how Pods get deleted. Once you're done, we'll explore a completely different, yet somehow the same type of Kubernetes workloads.</p>
<h2 id="daemonsets-in-kubernetes">DaemonSets in Kubernetes</h2>
<p>The next Kubernetes workload type is DaemonSet. I already prepared a manifest. Instead taking a look at it directly, we'll explore the difference compared with the one that contains the Deployment.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">diff deployment/base.yaml daemonset/base.yaml
</span></span></code></pre></div><p>The output is as follows.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln"> 1</span><span class="cl">2c2
</span></span><span class="line"><span class="ln"> 2</span><span class="cl">&lt; kind: Deployment
</span></span><span class="line"><span class="ln"> 3</span><span class="cl">---
</span></span><span class="line"><span class="ln"> 4</span><span class="cl">&gt; kind: DaemonSet
</span></span><span class="line"><span class="ln"> 5</span><span class="cl">8,13d7
</span></span><span class="line"><span class="ln"> 6</span><span class="cl">&lt;   replicas: 5
</span></span><span class="line"><span class="ln"> 7</span><span class="cl">&lt;   minReadySeconds: 10
</span></span><span class="line"><span class="ln"> 8</span><span class="cl">&lt;   strategy:
</span></span><span class="line"><span class="ln"> 9</span><span class="cl">&lt;     rollingUpdate:
</span></span><span class="line"><span class="ln">10</span><span class="cl">&lt;       maxUnavailable: 1
</span></span><span class="line"><span class="ln">11</span><span class="cl">&lt;       maxSurge: 1
</span></span></code></pre></div><p>There is the obvious change in the <code>kind</code> that is now set to <code>DaemonSet</code>, but also in some fields missing. It would not make sense to specify <code>replicas</code>, <code>strategy</code> and quite a few other things that might be useful for Deployments or StatefulSets. &quot;Why?&quot; you might ask. Well... Let me show it in action before I answer that question.</p>
<p>Let's apply the manifest,...</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">kubectl --namespace a-team apply --filename daemonset/base.yaml
</span></span></code></pre></div><p>...and output the ownership tree.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">kubectl tree --namespace a-team daemonset silly-demo
</span></span></code></pre></div><p>The output is as follows.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln">1</span><span class="cl">NAMESPACE NAME                                      READY REASON AGE
</span></span><span class="line"><span class="ln">2</span><span class="cl">a-team    DaemonSet/silly-demo                      -            4s 
</span></span><span class="line"><span class="ln">3</span><span class="cl">a-team    ‚îú‚îÄControllerRevision/silly-demo-5f76b8d84 -            4s 
</span></span><span class="line"><span class="ln">4</span><span class="cl">a-team    ‚îú‚îÄPod/silly-demo-6w5fb                    True         4s 
</span></span><span class="line"><span class="ln">5</span><span class="cl">a-team    ‚îú‚îÄPod/silly-demo-mhpcj                    True         4s 
</span></span><span class="line"><span class="ln">6</span><span class="cl">a-team    ‚îî‚îÄPod/silly-demo-wrdrs                    True         4s
</span></span></code></pre></div><p>This might look strange. The <code>DaemonSet</code> created three <code>Pods</code> even though we did not specify any number of replicas. Why are there three Pods and not one, or five, or any other number?</p>
<p>To understand that, we need to output the nodes of the cluster.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">kubectl get nodes
</span></span></code></pre></div><p>The output is as follows.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln">1</span><span class="cl">NAME               STATUS ROLES         AGE VERSION
</span></span><span class="line"><span class="ln">2</span><span class="cl">kind-control-plane Ready  control-plane 31m v1.29.2
</span></span><span class="line"><span class="ln">3</span><span class="cl">kind-worker        Ready  &lt;none&gt;        30m v1.29.2
</span></span><span class="line"><span class="ln">4</span><span class="cl">kind-worker2       Ready  &lt;none&gt;        30m v1.29.2
</span></span><span class="line"><span class="ln">5</span><span class="cl">kind-worker3       Ready  &lt;none&gt;        30m v1.29.2
</span></span></code></pre></div><p>If we exclude the <code>control-plane</code> node that, typically, should not have any workloads, there are three <code>worker</code> nodes. That can lead you to guess what DaemonSets do. They guarantee that a Pod will run in every single worked node of a cluster.</p>
<p>Here's what happened.</p>
<img src="diag-06.png" style="width:50%; float:right; padding: 10px">
<p>We have a Kubernetes cluster with a control plane  and three worker nodes . We applied a DaemonSet  which, in turn, ensured that there is a Pod based on the template in every single node of the cluster . If we would add more nodes to the cluster , the DaemonSet would ensure that a Pod is running there as well . If we would remove a node ... nothing would happen. We would have one less node and with it gone, one less Pod.</p>
<p>All that begs yet another &quot;Why?&quot;. Why would any want an instance running in every single node? Well... That's very useful for types of applications that are specific to nodes. An example could be log collection. Tools like Fluentd run as DaemonSets since they need to collect and ship logs from each node of a cluster. A similar need exists for observability tools and many others. More often than not, DaemonSets are used by third-party tools, but there might be cases when your apps should also run on every node of a cluster.</p>
<p>We're not yet done though. There are a few other workload APIs we should explore, so let's remove the DaemonSet and move on.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">kubectl --namespace a-team delete --filename daemonset/base.yaml
</span></span></code></pre></div><p>The next in line are Jobs.</p>
<h2 id="jobs-in-kubernetes">Jobs in Kubernetes</h2>
<p>All the workload types we explored so far are meant to be used for long running processes. If a main process in a container stops, the container itself would stop and, with it, Pod would be considered unhealthy. If such a Pod was created through a ReplicaSet, StatefulSet, or a DaemonSet, it would be recreated. All those assume that the contract means that they should ensure that specific number of Pods should run forever and ever. More often than not, that's what we want.</p>
<p>However, there are cases when we want to execute a process that does something and, once it's finished, shuts itself down and dissapears. A typical use-case for such processes would be batch processing, pipeline builds, and other one-shot actions.</p>
<p>Fortunately, Kubernetes has <strong>Jobs</strong> which are a type workload designed to do just that.</p>
<p>Let's take a look at yet another manifest.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">cat job/base.yaml
</span></span></code></pre></div><p>The output is as follows.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="ln"> 1</span><span class="cl"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">batch/v1</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 2</span><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Job</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 3</span><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 4</span><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">silly-demo</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 5</span><span class="cl"><span class="w">  </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 6</span><span class="cl"><span class="w">    </span><span class="nt">app.kubernetes.io/name</span><span class="p">:</span><span class="w"> </span><span class="l">silly-demo</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 7</span><span class="cl"><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 8</span><span class="cl"><span class="w">  </span><span class="nt">template</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 9</span><span class="cl"><span class="w">    </span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">10</span><span class="cl"><span class="w">      </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">11</span><span class="cl"><span class="w">        </span><span class="nt">app.kubernetes.io/name</span><span class="p">:</span><span class="w"> </span><span class="l">silly-demo</span><span class="w">
</span></span></span><span class="line"><span class="ln">12</span><span class="cl"><span class="w">    </span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">13</span><span class="cl"><span class="w">      </span><span class="nt">restartPolicy</span><span class="p">:</span><span class="w"> </span><span class="l">OnFailure</span><span class="w">
</span></span></span><span class="line"><span class="ln">14</span><span class="cl"><span class="w">      </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">15</span><span class="cl"><span class="w">        </span>- <span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">cgr.dev/chainguard/bash</span><span class="w">
</span></span></span><span class="line"><span class="ln">16</span><span class="cl"><span class="w">          </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">silly-demo</span><span class="w">
</span></span></span><span class="line"><span class="ln">17</span><span class="cl"><span class="w">          </span><span class="nt">command</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&#34;echo&#34;</span><span class="p">,</span><span class="w"> </span><span class="s2">&#34;What is this?&#34;</span><span class="p">]</span><span class="w">
</span></span></span></code></pre></div><p>This is a <code>Job</code>. It is very similar to other workload types with a <code>template</code> that allows us to define the characteristics that will enable it to spin up Pods. The only notable difference is that we can set <code>restartPolicy</code> to be either Never or, as is the case of this example, to OnFailure. As a comparison, Deployments have that field set to hard-coded value Always.</p>
<p>That field alone gives a clear indication what a Job does. While Pods created through Deployments are always restarted or recreated, no matter the reason they might fail, those created through Jobs are either never restarted, or only in case they fail. If the process running in a container ends running successfully by emitting status code 0, Job that created it will make no attempt to start it again.</p>
<p>Let's apply it,...</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">kubectl --namespace a-team apply --filename job/base.yaml
</span></span></code></pre></div><p>...and take a look at the ownership tree.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">kubectl tree --namespace a-team job silly-demo
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln">1</span><span class="cl">NAMESPACE NAME                   READY REASON       AGE
</span></span><span class="line"><span class="ln">2</span><span class="cl">a-team    Job/silly-demo         -                  11s
</span></span><span class="line"><span class="ln">3</span><span class="cl">a-team    ‚îî‚îÄPod/silly-demo-vn5xg False PodCompleted 11s
</span></span></code></pre></div><p>A Pod was created and it is no longer <code>READY</code>. That's okay since it completed doing whatever it was supposed to do, which, in this case, was to output &quot;What is this?&quot; message.</p>
<p>Now, even though the Pod is no longer running, we can still access the logs it created.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">kubectl --namespace a-team logs <span class="se">\
</span></span></span><span class="line"><span class="ln">2</span><span class="cl"><span class="se"></span>    --selector app.kubernetes.io/name<span class="o">=</span>silly-demo
</span></span></code></pre></div><p>The output is as follows.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln">1</span><span class="cl">What is this?
</span></span></code></pre></div><p>
  <figure>
  <picture>

    
      
        
        
        
        
        
        
    <img
      loading="lazy"
      decoding="async"
      alt=""
      
        class="image_figure image_internal image_processed"
        width="601"
        height="423"
        src="/post/workloads/diag-07.png"
      
      
    />

    </picture>
</figure>
</p>
<p>There we go. We sent a request to Kube API to apply a Job , a Job was created  and its controller created a Pod . The container in that Pod started a process that, eventually, finished doing whatever it was doing and returned exit code 0 . That was it. Unlike other workload types, the Job did not try to restart it or to recreate it.</p>
<p>The job finished, so let's remove it before we move into a next workload type.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">kubectl --namespace a-team delete --filename job/base.yaml
</span></span></code></pre></div><h2 id="cronjobs-in-kubernetes">CronJobs in Kubernetes</h2>
<p>Being able to run run Job as we just did is often great when creation of those jobs is triggered by something. For example, if we would run CI/CD pipelines in Kubernetes, those pipelines would be Jobs triggered by some events like pushing code to a Git repo, container images to a registry, uploads to an S3 drive, and so on and so forth. There are, however, cases, when we do not have such triggers but would like to run jobs periodically. A good example would be scheduled backups. In those cases, we can use <strong>CronJobs</strong>.</p>
<p>Here's an example.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">cat cronjob/base.yaml
</span></span></code></pre></div><p>The output is as follows.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="ln"> 1</span><span class="cl"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">batch/v1</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 2</span><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">CronJob</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 3</span><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 4</span><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">silly-demo</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 5</span><span class="cl"><span class="w">  </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 6</span><span class="cl"><span class="w">    </span><span class="nt">app.kubernetes.io/name</span><span class="p">:</span><span class="w"> </span><span class="l">silly-demo</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 7</span><span class="cl"><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 8</span><span class="cl"><span class="w">  </span><span class="nt">schedule</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;*/1 * * * *&#34;</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 9</span><span class="cl"><span class="w">  </span><span class="nt">jobTemplate</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">10</span><span class="cl"><span class="w">    </span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">11</span><span class="cl"><span class="w">      </span><span class="nt">template</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">12</span><span class="cl"><span class="w">        </span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">13</span><span class="cl"><span class="w">          </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">14</span><span class="cl"><span class="w">            </span><span class="nt">app.kubernetes.io/name</span><span class="p">:</span><span class="w"> </span><span class="l">silly-demo</span><span class="w">
</span></span></span><span class="line"><span class="ln">15</span><span class="cl"><span class="w">        </span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">16</span><span class="cl"><span class="w">          </span><span class="nt">restartPolicy</span><span class="p">:</span><span class="w"> </span><span class="l">OnFailure</span><span class="w">
</span></span></span><span class="line"><span class="ln">17</span><span class="cl"><span class="w">          </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">18</span><span class="cl"><span class="w">            </span>- <span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">cgr.dev/chainguard/bash</span><span class="w">
</span></span></span><span class="line"><span class="ln">19</span><span class="cl"><span class="w">              </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">silly-demo</span><span class="w">
</span></span></span><span class="line"><span class="ln">20</span><span class="cl"><span class="w">              </span><span class="nt">command</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&#34;echo&#34;</span><span class="p">,</span><span class="w"> </span><span class="s2">&#34;What is this?&#34;</span><span class="p">]</span><span class="w">
</span></span></span></code></pre></div><p>The <code>kind</code> is, this time, <code>CronJob</code>. It contains <code>schedule</code> that uses a standard Linux cronjob syntax to define frequency of execution, and a <code>jobTemplate</code>. In this case, the Job will run every minute.</p>
<p>Just as Deployments are types of resources that manage ReplicaSets, CronJobs manage Jobs. So, <code>jobTemplate</code> tells CronJob how to create Jobs and, in this case, the content of the template is pretty much the same as what we had in the Job.</p>
<p>Let's apply it,...</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">kubectl --namespace a-team apply --filename cronjob/base.yaml
</span></span></code></pre></div><p>...and take a look at the CronJobs inside the <code>a-team</code> Namespace.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">kubectl --namespace a-team get cronjobs
</span></span></code></pre></div><p>The output is as follows.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln">1</span><span class="cl">NAME       SCHEDULE    SUSPEND ACTIVE LAST SCHEDULE AGE
</span></span><span class="line"><span class="ln">2</span><span class="cl">silly-demo */1 * * * * False   0      22s           35s
</span></span></code></pre></div><p>You can probably guess what those fields mean, so let's watch the Pods that should be created by that Job.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">viddy kubectl --namespace a-team get pods
</span></span></code></pre></div><p>The output is as follows.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln">1</span><span class="cl">NAME                      READY STATUS            RESTARTS AGE
</span></span><span class="line"><span class="ln">2</span><span class="cl">silly-demo-28521541-wzj7f 0/1   Completed         0        63s
</span></span><span class="line"><span class="ln">3</span><span class="cl">silly-demo-28521542-pt5hp 0/1   ContainerCreating 0        3s
</span></span><span class="line"><span class="ln">4</span><span class="cl">...
</span></span></code></pre></div><p>We can see that the first Pod was created. Let's fast-forward to the next minute and... there we go. The second Pod was created... and the third, and so on and so forth.</p>
<p><em>Stop watching by pressing <code>ctrl+c</code>.</em></p>
<p>We explored all workload resources baked into Kubernetes, but there's more, much more. Baked-in resource types are only the tip of the iceberg.</p>
<p>Let's destroy the CronJob before we move on.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">kubectl --namespace a-team delete --filename cronjob/base.yaml
</span></span></code></pre></div><h2 id="goodbye-for-now">Goodbye (For Now)</h2>
<p>Resource definitions baked into Kubernetes are more more like building blocks than something we should use dirctly. We can accomplish so much more if we add projects that use those blocks and provide higher levels of abstractions. Unfortunately, we don't have time to go through those, especially since the number of those extensions and abstractions is close to infinite. We could be using Knative, Cloud-Native PostgreSQL or CNPG, and many other third-party CRDs and controllers or we could build our own. You can find examples of quite a few of such solutions on this channel.</p>
<p>Now I have a question for you.
Was this video useful? Would it make sense to continue through other Kubernetes API groups? If it does, which one would you like to see next? Service API? Config and storage APIs? Something else?</p>
<p>Let me know in the comments.</p>
<p>Thank you for watching.
See you in the next one.
Cheers.</p>
<h2 id="destroy">Destroy</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">kind delete cluster
</span></span><span class="line"><span class="ln">2</span><span class="cl">
</span></span><span class="line"><span class="ln">3</span><span class="cl">git checkout main
</span></span><span class="line"><span class="ln">4</span><span class="cl">
</span></span><span class="line"><span class="ln">5</span><span class="cl"><span class="nb">exit</span>
</span></span></code></pre></div>
    </div>
<div class="post_comments">
  
  
  
</div>




  </article>
<aside class="sidebar">
  <section class="sidebar_inner">
    <br>
    
  
  <div class="search">
    <input type="search" class="search_field form_field" placeholder='Search...' id="find" autocomplete="off" data-scope='post'>
    <label for="find" class="search_label"><svg class="icon">
  <title>search</title>
  <use xlink:href="#search"></use>
</svg>

    </label>
    
    <div class="search_results results"></div>
  </div>


    
    
    <h2 class="mt-4">Recent Posts</h2>
    <ul class="flex-column">
    </ul>
  </section>
</aside>

  
</div>
    </main><svg width="0" height="0" class="hidden">
  <symbol viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" id="facebook">
    <path d="M437 0H75C33.648 0 0 33.648 0 75v362c0 41.352 33.648 75 75 75h151V331h-60v-90h60v-61c0-49.629 40.371-90 90-90h91v90h-91v61h91l-15 90h-76v181h121c41.352 0 75-33.648 75-75V75c0-41.352-33.648-75-75-75zm0 0"></path>
  </symbol>
  <symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 18.001 18.001" id="twitter">
    <path d="M15.891 4.013c.808-.496 1.343-1.173 1.605-2.034a8.68 8.68 0 0 1-2.351.861c-.703-.756-1.593-1.14-2.66-1.14-1.043 0-1.924.366-2.643 1.078a3.56 3.56 0 0 0-1.076 2.605c0 .309.039.585.117.819-3.076-.105-5.622-1.381-7.628-3.837-.34.601-.51 1.213-.51 1.846 0 1.301.549 2.332 1.645 3.089-.625-.053-1.176-.211-1.645-.47 0 .929.273 1.705.82 2.388a3.623 3.623 0 0 0 2.115 1.291c-.312.08-.641.118-.979.118-.312 0-.533-.026-.664-.083.23.757.664 1.371 1.291 1.841a3.652 3.652 0 0 0 2.152.743C4.148 14.173 2.625 14.69.902 14.69c-.422 0-.721-.006-.902-.038 1.697 1.102 3.586 1.649 5.676 1.649 2.139 0 4.029-.542 5.674-1.626 1.645-1.078 2.859-2.408 3.639-3.974a10.77 10.77 0 0 0 1.172-4.892v-.468a7.788 7.788 0 0 0 1.84-1.921 8.142 8.142 0 0 1-2.11.593z"
      ></path>
  </symbol>
  <symbol aria-hidden="true" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" id="mail">
    <path  d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"></path>
  </symbol>
  <symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" id="calendar">
    <path d="M452 40h-24V0h-40v40H124V0H84v40H60C26.916 40 0 66.916 0 100v352c0 33.084 26.916 60 60 60h392c33.084 0 60-26.916 60-60V100c0-33.084-26.916-60-60-60zm20 412c0 11.028-8.972 20-20 20H60c-11.028 0-20-8.972-20-20V188h432v264zm0-304H40v-48c0-11.028 8.972-20 20-20h24v40h40V80h264v40h40V80h24c11.028 0 20 8.972 20 20v48z"></path>
    <path d="M76 230h40v40H76zm80 0h40v40h-40zm80 0h40v40h-40zm80 0h40v40h-40zm80 0h40v40h-40zM76 310h40v40H76zm80 0h40v40h-40zm80 0h40v40h-40zm80 0h40v40h-40zM76 390h40v40H76zm80 0h40v40h-40zm80 0h40v40h-40zm80 0h40v40h-40zm80-80h40v40h-40z"></path>
  </symbol>
  <symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" id="github">
    <path d="M255.968 5.329C114.624 5.329 0 120.401 0 262.353c0 113.536 73.344 209.856 175.104 243.872 12.8 2.368 17.472-5.568 17.472-12.384 0-6.112-.224-22.272-.352-43.712-71.2 15.52-86.24-34.464-86.24-34.464-11.616-29.696-28.416-37.6-28.416-37.6-23.264-15.936 1.728-15.616 1.728-15.616 25.696 1.824 39.2 26.496 39.2 26.496 22.848 39.264 59.936 27.936 74.528 21.344 2.304-16.608 8.928-27.936 16.256-34.368-56.832-6.496-116.608-28.544-116.608-127.008 0-28.064 9.984-51.008 26.368-68.992-2.656-6.496-11.424-32.64 2.496-68 0 0 21.504-6.912 70.4 26.336 20.416-5.696 42.304-8.544 64.096-8.64 21.728.128 43.648 2.944 64.096 8.672 48.864-33.248 70.336-26.336 70.336-26.336 13.952 35.392 5.184 61.504 2.56 68 16.416 17.984 26.304 40.928 26.304 68.992 0 98.72-59.84 120.448-116.864 126.816 9.184 7.936 17.376 23.616 17.376 47.584 0 34.368-.32 62.08-.32 70.496 0 6.88 4.608 14.88 17.6 12.352C438.72 472.145 512 375.857 512 262.353 512 120.401 397.376 5.329 255.968 5.329z"></path>
  </symbol>
  <symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 212 212" id="gitlab">
    <path d="M12.3 74.7h54L43.3 3c-1-3.6-6.4-3.6-7.6 0L12.3 74.8z" />
    <path d="M12.3 74.7L.5 111c-1 3.2 0 6.8 3 8.8l101.6 74-92.5-119z"/>
    <path d="M105 193.7l-38.6-119h-54l92.7 119z"/>
    <path d="M105 193.7l38.7-119H66.4l38.7 119z"/>
    <path d="M105 193.7l38.7-119H198l-93 119z"/>
    <path d="M198 74.7l11.6 36.2c1 3 0 6.6-3 8.6l-101.5 74 93-119z"/>
    <path d="M198 74.7h-54.3L167 3c1.2-3.6 6.4-3.6 7.6 0L198 74.8z"/>
  </symbol>
  <symbol viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" id="rss">
    <circle cx="3.429" cy="20.571" r="3.429"></circle>
    <path d="M11.429 24h4.57C15.999 15.179 8.821 8.001 0 8v4.572c6.302.001 11.429 5.126 11.429 11.428z"></path>
    <path d="M24 24C24 10.766 13.234 0 0 0v4.571c10.714 0 19.43 8.714 19.43 19.429z"></path>
  </symbol>
  <symbol viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" id="linkedin">
    <path d="M437 0H75C33.648 0 0 33.648 0 75v362c0 41.352 33.648 75 75 75h362c41.352 0 75-33.648 75-75V75c0-41.352-33.648-75-75-75zM181 406h-60V196h60zm0-240h-60v-60h60zm210 240h-60V286c0-16.54-13.46-30-30-30s-30 13.46-30 30v120h-60V196h60v11.309C286.719 202.422 296.93 196 316 196c40.691.043 75 36.547 75 79.688zm0 0"></path>
  </symbol>
  <symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 612 612" id="to-top">
    <path d="M604.501 440.509L325.398 134.956c-5.331-5.357-12.423-7.627-19.386-7.27-6.989-.357-14.056 1.913-19.387 7.27L7.499 440.509c-9.999 10.024-9.999 26.298 0 36.323s26.223 10.024 36.222 0l262.293-287.164L568.28 476.832c9.999 10.024 26.222 10.024 36.221 0 9.999-10.023 9.999-26.298 0-36.323z"></path>
  </symbol>
  <symbol viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" id="carly">
    <path d="M504.971 239.029L448 182.059V84c0-46.317-37.682-84-84-84h-44c-13.255 0-24 10.745-24 24s10.745 24 24 24h44c19.851 0 36 16.149 36 36v108c0 6.365 2.529 12.47 7.029 16.971L454.059 256l-47.029 47.029A24.002 24.002 0 0 0 400 320v108c0 19.851-16.149 36-36 36h-44c-13.255 0-24 10.745-24 24s10.745 24 24 24h44c46.318 0 84-37.683 84-84v-98.059l56.971-56.971c9.372-9.372 9.372-24.568 0-33.941zM112 192V84c0-19.851 16.149-36 36-36h44c13.255 0 24-10.745 24-24S205.255 0 192 0h-44c-46.318 0-84 37.683-84 84v98.059l-56.971 56.97c-9.373 9.373-9.373 24.568 0 33.941L64 329.941V428c0 46.317 37.682 84 84 84h44c13.255 0 24-10.745 24-24s-10.745-24-24-24h-44c-19.851 0-36-16.149-36-36V320c0-6.365-2.529-12.47-7.029-16.971L57.941 256l47.029-47.029A24.002 24.002 0 0 0 112 192z"></path>
  </symbol>
  <symbol viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" id="copy">
    <path d="M23 2.75A2.75 2.75 0 0 0 20.25 0H8.75A2.75 2.75 0 0 0 6 2.75v13.5A2.75 2.75 0 0 0 8.75 19h11.5A2.75 2.75 0 0 0 23 16.25zM18.25 14.5h-7.5a.75.75 0 0 1 0-1.5h7.5a.75.75 0 0 1 0 1.5zm0-3h-7.5a.75.75 0 0 1 0-1.5h7.5a.75.75 0 0 1 0 1.5zm0-3h-7.5a.75.75 0 0 1 0-1.5h7.5a.75.75 0 0 1 0 1.5z"></path>
    <path d="M8.75 20.5a4.255 4.255 0 0 1-4.25-4.25V2.75c0-.086.02-.166.025-.25H3.75A2.752 2.752 0 0 0 1 5.25v16A2.752 2.752 0 0 0 3.75 24h12a2.752 2.752 0 0 0 2.75-2.75v-.75z"></path>
  </symbol>
  <symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512.001 512.001" id="closeme">
    <path d="M284.286 256.002L506.143 34.144c7.811-7.811 7.811-20.475 0-28.285-7.811-7.81-20.475-7.811-28.285 0L256 227.717 34.143 5.859c-7.811-7.811-20.475-7.811-28.285 0-7.81 7.811-7.811 20.475 0 28.285l221.857 221.857L5.858 477.859c-7.811 7.811-7.811 20.475 0 28.285a19.938 19.938 0 0 0 14.143 5.857 19.94 19.94 0 0 0 14.143-5.857L256 284.287l221.857 221.857c3.905 3.905 9.024 5.857 14.143 5.857s10.237-1.952 14.143-5.857c7.811-7.811 7.811-20.475 0-28.285L284.286 256.002z"></path>
  </symbol>
  <symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" id="open-menu">
    <path d="M492 236H20c-11.046 0-20 8.954-20 20s8.954 20 20 20h472c11.046 0 20-8.954 20-20s-8.954-20-20-20zm0-160H20C8.954 76 0 84.954 0 96s8.954 20 20 20h472c11.046 0 20-8.954 20-20s-8.954-20-20-20zm0 320H20c-11.046 0-20 8.954-20 20s8.954 20 20 20h472c11.046 0 20-8.954 20-20s-8.954-20-20-20z"></path>
  </symbol>
  <symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" id="instagram">
    <path d="M12 2.163c3.204 0 3.584.012 4.85.07 3.252.148 4.771 1.691 4.919 4.919.058 1.265.069 1.645.069 4.849 0 3.205-.012 3.584-.069 4.849-.149 3.225-1.664 4.771-4.919 4.919-1.266.058-1.644.07-4.85.07-3.204 0-3.584-.012-4.849-.07-3.26-.149-4.771-1.699-4.919-4.92-.058-1.265-.07-1.644-.07-4.849 0-3.204.013-3.583.07-4.849.149-3.227 1.664-4.771 4.919-4.919 1.266-.057 1.645-.069 4.849-.069zm0-2.163c-3.259 0-3.667.014-4.947.072-4.358.2-6.78 2.618-6.98 6.98-.059 1.281-.073 1.689-.073 4.948 0 3.259.014 3.668.072 4.948.2 4.358 2.618 6.78 6.98 6.98 1.281.058 1.689.072 4.948.072 3.259 0 3.668-.014 4.948-.072 4.354-.2 6.782-2.618 6.979-6.98.059-1.28.073-1.689.073-4.948 0-3.259-.014-3.667-.072-4.947-.196-4.354-2.617-6.78-6.979-6.98-1.281-.059-1.69-.073-4.949-.073zm0 5.838c-3.403 0-6.162 2.759-6.162 6.162s2.759 6.163 6.162 6.163 6.162-2.759 6.162-6.163c0-3.403-2.759-6.162-6.162-6.162zm0 10.162c-2.209 0-4-1.79-4-4 0-2.209 1.791-4 4-4s4 1.791 4 4c0 2.21-1.791 4-4 4zm6.406-11.845c-.796 0-1.441.645-1.441 1.44s.645 1.44 1.441 1.44c.795 0 1.439-.645 1.439-1.44s-.644-1.44-1.439-1.44z"/>
  </symbol>
  <symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" id=youtube>
    <path d="M19.615 3.184c-3.604-.246-11.631-.245-15.23 0-3.897.266-4.356 2.62-4.385 8.816.029 6.185.484 8.549 4.385 8.816 3.6.245 11.626.246 15.23 0 3.897-.266 4.356-2.62 4.385-8.816-.029-6.185-.484-8.549-4.385-8.816zm-10.615 12.816v-8l8 3.993-8 4.007z"/>
  </symbol>
  <symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" id="stackoverflow">
    <path d="M21 27v-8h3v11H0V19h3v8h18z"></path><path d="M17.1.2L15 1.8l7.9 10.6 2.1-1.6L17.1.2zm3.7 14.7L10.6 6.4l1.7-2 10.2 8.5-1.7 2zM7.2 12.3l12 5.6 1.1-2.4-12-5.6-1.1 2.4zm-1.8 6.8l13.56 1.96.17-2.38-13.26-2.55-.47 2.97zM19 25H5v-3h14v3z"></path>
  </symbol>
  <symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" id="xing">
    <path d="M18.188 0c-.517 0-.741.325-.927.66 0 0-7.455 13.224-7.702 13.657.015.024 4.919 9.023 4.919 9.023.17.308.436.66.967.66h3.454c.211 0 .375-.078.463-.22.089-.151.089-.346-.009-.536l-4.879-8.916c-.004-.006-.004-.016 0-.022L22.139.756c.095-.191.097-.387.006-.535C22.056.078 21.894 0 21.686 0h-3.498zM3.648 4.74c-.211 0-.385.074-.473.216-.09.149-.078.339.02.531l2.34 4.05c.004.01.004.016 0 .021L1.86 16.051c-.099.188-.093.381 0 .529.085.142.239.234.45.234h3.461c.518 0 .766-.348.945-.667l3.734-6.609-2.378-4.155c-.172-.315-.434-.659-.962-.659H3.648v.016z"/>
  </symbol>
  <symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 71 55" id="discord">
    <path d="M60.1045 4.8978C55.5792 2.8214 50.7265 1.2916 45.6527 0.41542C45.5603 0.39851 45.468 0.440769 45.4204 0.525289C44.7963 1.6353 44.105 3.0834 43.6209 4.2216C38.1637 3.4046 32.7345 3.4046 27.3892 4.2216C26.905 3.0581 26.1886 1.6353 25.5617 0.525289C25.5141 0.443589 25.4218 0.40133 25.3294 0.41542C20.2584 1.2888 15.4057 2.8186 10.8776 4.8978C10.8384 4.9147 10.8048 4.9429 10.7825 4.9795C1.57795 18.7309 -0.943561 32.1443 0.293408 45.3914C0.299005 45.4562 0.335386 45.5182 0.385761 45.5576C6.45866 50.0174 12.3413 52.7249 18.1147 54.5195C18.2071 54.5477 18.305 54.5139 18.3638 54.4378C19.7295 52.5728 20.9469 50.6063 21.9907 48.5383C22.0523 48.4172 21.9935 48.2735 21.8676 48.2256C19.9366 47.4931 18.0979 46.6 16.3292 45.5858C16.1893 45.5041 16.1781 45.304 16.3068 45.2082C16.679 44.9293 17.0513 44.6391 17.4067 44.3461C17.471 44.2926 17.5606 44.2813 17.6362 44.3151C29.2558 49.6202 41.8354 49.6202 53.3179 44.3151C53.3935 44.2785 53.4831 44.2898 53.5502 44.3433C53.9057 44.6363 54.2779 44.9293 54.6529 45.2082C54.7816 45.304 54.7732 45.5041 54.6333 45.5858C52.8646 46.6197 51.0259 47.4931 49.0921 48.2228C48.9662 48.2707 48.9102 48.4172 48.9718 48.5383C50.038 50.6034 51.2554 52.5699 52.5959 54.435C52.6519 54.5139 52.7526 54.5477 52.845 54.5195C58.6464 52.7249 64.529 50.0174 70.6019 45.5576C70.6551 45.5182 70.6887 45.459 70.6943 45.3942C72.1747 30.0791 68.2147 16.7757 60.1968 4.9823C60.1772 4.9429 60.1437 4.9147 60.1045 4.8978ZM23.7259 37.3253C20.2276 37.3253 17.3451 34.1136 17.3451 30.1693C17.3451 26.225 20.1717 23.0133 23.7259 23.0133C27.308 23.0133 30.1626 26.2532 30.1066 30.1693C30.1066 34.1136 27.28 37.3253 23.7259 37.3253ZM47.3178 37.3253C43.8196 37.3253 40.9371 34.1136 40.9371 30.1693C40.9371 26.225 43.7636 23.0133 47.3178 23.0133C50.9 23.0133 53.7545 26.2532 53.6986 30.1693C53.6986 34.1136 50.9 37.3253 47.3178 37.3253Z"/>
  </symbol>
  <symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 17 18" id="mastodon">
    <path
    fill="#ffffff"
    d="m 15.054695,9.8859583 c -0.22611,1.1632697 -2.02517,2.4363497 -4.09138,2.6830797 -1.0774504,0.12856 -2.1382704,0.24673 -3.2694704,0.19484 -1.84996,-0.0848 -3.30971,-0.44157 -3.30971,-0.44157 0,0.1801 0.0111,0.35157 0.0333,0.51194 0.24051,1.82571 1.81034,1.93508 3.29737,1.98607 1.50088,0.0514 2.8373104,-0.37004 2.8373104,-0.37004 l 0.0617,1.35686 c 0,0 -1.0498104,0.56374 -2.9199404,0.66742 -1.03124,0.0567 -2.3117,-0.0259 -3.80308,-0.42069 -3.23454998,-0.85613 -3.79081998,-4.304 -3.87592998,-7.8024197 -0.026,-1.03871 -0.01,-2.01815 -0.01,-2.83732 0,-3.57732 2.34385998,-4.62587996 2.34385998,-4.62587996 1.18184,-0.54277 3.20976,-0.77101 5.318,-0.7882499985409 h 0.0518 C 9.8267646,0.01719834 11.856025,0.24547834 13.037775,0.78824834 c 0,0 2.34377,1.04855996 2.34377,4.62587996 0,0 0.0294,2.63937 -0.32687,4.47183"/>
 <path
    fill="#000000"
    d="m 12.616925,5.6916583 v 4.3315297 h -1.71607 V 5.8189683 c 0,-0.88624 -0.37289,-1.33607 -1.1187604,-1.33607 -0.82467,0 -1.23799,0.53361 -1.23799,1.58875 v 2.30122 h -1.70594 v -2.30122 c 0,-1.05514 -0.4134,-1.58875 -1.23808,-1.58875 -0.74587,0 -1.11876,0.44983 -1.11876,1.33607 v 4.2042197 h -1.71607 V 5.6916583 c 0,-0.88527 0.22541,-1.58876 0.67817,-2.10922 0.46689,-0.52047 1.07833,-0.78727 1.83735,-0.78727 0.87816,0 1.54317,0.33752 1.98288,1.01267 l 0.42744,0.71655 0.42753,-0.71655 c 0.43961,-0.67515 1.10463,-1.01267 1.9828704,-1.01267 0.75893,0 1.37037,0.2668 1.83735,0.78727 0.45268,0.52046 0.67808,1.22395 0.67808,2.10922"/>
  </symbol>
</svg>

<footer class="footer">
  <div class="footer_inner wrap pale">
    <img src='http://localhost:1313/icons/apple-touch-icon.png' class="icon icon_2 transparent" alt="Copyright ¬© 2008‚Äì2018, Steve Francia and the Hugo Authors; all rights reserved.">
    <p>Copyright&nbsp;<span class="year"></span>&nbsp;COPYRIGHT ¬© 2008‚Äì2018, STEVE FRANCIA AND THE HUGO AUTHORS; ALL RIGHTS RESERVED.. All Rights Reserved</p><a class="to_top" href="#documentTop">
  <svg class="icon">
  <title>to-top</title>
  <use xlink:href="#to-top"></use>
</svg>

</a>

  </div>
</footer>

<script type="text/javascript" src="http://localhost:1313/en/js/bundle.0d036cc8bad2080f4c50d1ad5c14f6106a56b6d12ac69457cb6219c7fcb4181e1ecae48e5a844297763c02a18426d0f0811d2cb368792861cb42618660b894d9.js" integrity="sha512-DQNsyLrSCA9MUNGtXBT2EGpWttEqxpRXy2IZx/y0GB4eyuSOWoRCl3Y8AqGEJtDwgR0ss2h5KGHLQmGGYLiU2Q==" crossorigin="anonymous"></script>

  <script src="http://localhost:1313/js/search.min.73cb82d8f274395dd220d6594053cd3d3d8ac8c97d874b5142a60b9744f3704d765551e0ade104d5803c66b731f5a7a00ac2cff33c8c9090ff8100169a3e2574.js"></script>

  </body>
</html>
